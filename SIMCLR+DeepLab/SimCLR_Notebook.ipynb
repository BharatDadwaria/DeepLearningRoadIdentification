{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SimCLR_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jF8ZoVrwt0n0"
      },
      "source": [
        "# SimCLR\n",
        "PyTorch implementation of SimCLR: A Simple Framework for Contrastive Learning of Visual Representations by T. Chen et al. With support for the LARS (Layer-wise Adaptive Rate Scaling) optimizer.\n",
        "\n",
        "[Link to paper](https://arxiv.org/pdf/2002.05709.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lt6WMxjCvN3o"
      },
      "source": [
        "## Setup the repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REWs4N56Cpwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/data/')\n",
        "#from pathlib import Path\n",
        "#base_dir = ('/data/My Drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypm0vMObCvM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!cp  /data/My\\ Drive/DeepLearning/student_data.zip /content/SimCLR\n",
        "#!unzip student_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "53JMIYtat8tT",
        "outputId": "6eb6d4c5-a013-48a4-9bc0-5764fa495d2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#!git clone https://github.com/AmeerHamza111/SimCLR.git\n",
        "%cd SimCLR\n",
        "#!wget https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar\n",
        "#!sh setup.sh || python3 -m pip install -r requirements.txt || exit 1\n",
        "#!pip install  pyyaml --upgrade"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SimCLR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fQ3jq3cWynLf"
      },
      "source": [
        "# Part 1:\n",
        "## SimCLR pre-training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0jhAv3hv8IHn",
        "colab": {}
      },
      "source": [
        "# whether to use a TPU or not (set in Runtime -> Change Runtime Type)\n",
        "use_tpu = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bwW10d2O7pn8"
      },
      "source": [
        "#### Install PyTorch/XLA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vj84aiC27oxS",
        "colab": {}
      },
      "source": [
        "if use_tpu:\n",
        "  VERSION = \"20200220\" #@param [\"20200220\",\"nightly\", \"xrt==1.15.0\"]\n",
        "  !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "  !python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oNDRcPbbymlX",
        "outputId": "4e27ead8-6a2c-4e91-ab0f-bc107a2bf1a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "if use_tpu:\n",
        "  # imports the torch_xla package for TPU support\n",
        "  import torch_xla\n",
        "  import torch_xla.core.xla_model as xm\n",
        "  dev = xm.xla_device()\n",
        "  print(dev)\n",
        "  \n",
        "import torchvision\n",
        "import argparse\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "apex = False\n",
        "try:\n",
        "    from apex import amp\n",
        "    apex = True\n",
        "except ImportError:\n",
        "    print(\n",
        "        \"Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\"\n",
        "    )\n",
        "\n",
        "from model import load_model, save_model\n",
        "from modules import NT_Xent\n",
        "from modules.transformations import TransformsSimCLR\n",
        "from utils import mask_correlated_samples, post_config_hook\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Abk6aFZxyedW",
        "colab": {}
      },
      "source": [
        "def train(args, train_loader, model, criterion, optimizer, writer):\n",
        "    loss_epoch = 0\n",
        "    for step, ((x_i, x_j), _) in enumerate(train_loader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        x_i = x_i.to(args.device)\n",
        "        x_j = x_j.to(args.device)\n",
        "\n",
        "        # positive pair, with encoding\n",
        "        h_i, z_i = model(x_i)\n",
        "        h_j, z_j = model(x_j)\n",
        "\n",
        "        loss = criterion(z_i, z_j)\n",
        "\n",
        "        if apex and args.fp16:\n",
        "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                scaled_loss.backward()\n",
        "        else:\n",
        "            loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if step % 50 == 0:\n",
        "            print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()}\")\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        writer.add_scalar(\"Loss/train_epoch\", loss.item(), args.global_step)\n",
        "        loss_epoch += loss.item()\n",
        "        args.global_step += 1\n",
        "\n",
        "    return loss_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eYbV0fa_y03Z"
      },
      "source": [
        "### Load arguments from `config/config.yaml`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1klUf-IuyxdL",
        "colab": {}
      },
      "source": [
        "from pprint import pprint\n",
        "from utils.yaml_config_hook import yaml_config_hook\n",
        "\n",
        "config = yaml_config_hook(\"./config/config.yaml\")\n",
        "args = argparse.Namespace(**config)\n",
        "\n",
        "if use_tpu:\n",
        "  args.device = dev\n",
        "else:\n",
        "  args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  \n",
        "args.out_dir = \"logs/simclrPretext\"\n",
        "if not os.path.exists(\"logs/simclrPretext\"):\n",
        "  os.makedirs(\"logs/simclrPretext\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O86__UhA0Lvr",
        "outputId": "94384edd-655b-45d4-ac2e-2cec2ddf2fad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "args.batch_size = 2\n",
        "args.epochs = 1\n",
        "args.epoch_num = 1\n",
        "args.resnet = \"resnet18\"\n",
        "args.dataset = \"road\"\n",
        "args.model_path = \"logs/simclrPretext\"\n",
        "#args.optimizer = \"LARS\"\n",
        "pprint(vars(args))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 2,\n",
            " 'dataset': 'road',\n",
            " 'device': device(type='cuda', index=0),\n",
            " 'epoch_num': 1,\n",
            " 'epochs': 1,\n",
            " 'fp16': False,\n",
            " 'fp16_opt_level': 'O2',\n",
            " 'logistic_batch_size': 256,\n",
            " 'logistic_epochs': 100,\n",
            " 'model_path': 'logs/simclrPretext',\n",
            " 'normalize': True,\n",
            " 'optimizer': 'Adam',\n",
            " 'out_dir': 'logs/simclrPretext',\n",
            " 'projection_dim': 64,\n",
            " 'resnet': 'resnet18',\n",
            " 'seed': 42,\n",
            " 'start_epoch': 0,\n",
            " 'temperature': 0.5,\n",
            " 'weight_decay': 1e-06,\n",
            " 'workers': 16}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTxjEiO3_VWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_folder = 'data'\n",
        "annotation_csv = 'data/annotation.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYLW1P01_VWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from data_helper import SimclrUnlabeledDataset\n",
        "from helper import convert_map_to_lane_map, convert_map_to_road_map, collate_fn, draw_box"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvkLYD-W_VWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_scene_index = np.arange(106)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gsweoKt_VW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fullDataset_scene_index = np.arange(134)  # Training on the simclr model on the entire dataset."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xJfeOM9PzNoF"
      },
      "source": [
        "### Load dataset into train loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YGcskdBsytbj",
        "colab": {}
      },
      "source": [
        "root = \"./datasets\"\n",
        "\n",
        "train_sampler = None\n",
        "\n",
        "if args.dataset == \"STL10\":\n",
        "    train_dataset = torchvision.datasets.STL10(\n",
        "        root, split=\"unlabeled\", download=True, transform=TransformsSimCLR()\n",
        "    )\n",
        "elif args.dataset == \"CIFAR10\":\n",
        "    train_dataset = torchvision.datasets.CIFAR10(\n",
        "        root, download=True, transform=TransformsSimCLR()\n",
        "    )\n",
        "elif args.dataset == \"road\":\n",
        "    train_dataset = SimclrUnlabeledDataset(image_folder=image_folder, \n",
        "      scene_index=fullDataset_scene_index, first_dim='sample', transform=TransformsSimCLR())\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    shuffle=(train_sampler is None),\n",
        "    drop_last=True,\n",
        "    num_workers=args.workers,\n",
        "    sampler=train_sampler,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHFCqA9x_VW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--NotebookApp.iopub_msg_rate_limit = 4000.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdI19WSQ_VW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OruStI0h_VW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RBlXZwvjzPmp"
      },
      "source": [
        "### Load the SimCLR model, optimizer and learning rate scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xERq_yHSzJRX",
        "colab": {}
      },
      "source": [
        "model, optimizer, scheduler = load_model(args, train_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHUP8kPY_VXE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "084b1778-89a0-4cd3-a772-ff4768f7c987"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SimCLR(\n",
            "  (encoder): ResNet(\n",
            "    (conv1): Conv2d(18, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Identity()\n",
            "  )\n",
            "  (projector): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=64, bias=False)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RyJ3ulWqzViL"
      },
      "source": [
        "### Setup TensorBoard for logging experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zZNieMqfzU7H",
        "colab": {}
      },
      "source": [
        "tb_dir = os.path.join(args.out_dir, \"colab\")\n",
        "if not os.path.exists(tb_dir):\n",
        "  os.makedirs(tb_dir)\n",
        "writer = SummaryWriter(log_dir=tb_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xpl6uQiIzbvK"
      },
      "source": [
        "### Create the mask that will remove correlated samples from the negative examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nik6l8ihzZ42",
        "colab": {}
      },
      "source": [
        "mask = mask_correlated_samples(args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dtNCVEynzjtV"
      },
      "source": [
        "### Initialize the criterion (NT-Xent loss)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u067AY93zh-k",
        "colab": {}
      },
      "source": [
        "criterion = NT_Xent(args.batch_size, args.temperature, mask, args.device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cN5KBK-yztGD"
      },
      "source": [
        "### Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TdCrD62hzjDQ",
        "outputId": "f4c97e48-3d81-44da-d805-6f898d7a2d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''args.global_step = 0\n",
        "args.current_epoch = 0\n",
        "for epoch in range(args.start_epoch, args.epochs):\n",
        "    lr = optimizer.param_groups[0]['lr']\n",
        "    loss_epoch = train(args, train_loader, model, criterion, optimizer, writer)\n",
        "\n",
        "    if scheduler:\n",
        "        scheduler.step()\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        save_model(args, model, optimizer)\n",
        "\n",
        "    writer.add_scalar(\"Loss/train\", loss_epoch / len(train_loader), epoch)\n",
        "    writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\n",
        "    print(\n",
        "        f\"Epoch [{epoch}/{args.epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t lr: {round(lr, 5)}\"\n",
        "    )\n",
        "    args.current_epoch += 1\n",
        "\n",
        "## end training\n",
        "save_model(args, model, optimizer)'''"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'args.global_step = 0\\nargs.current_epoch = 0\\nfor epoch in range(args.start_epoch, args.epochs):\\n    lr = optimizer.param_groups[0][\\'lr\\']\\n    loss_epoch = train(args, train_loader, model, criterion, optimizer, writer)\\n\\n    if scheduler:\\n        scheduler.step()\\n\\n    if epoch % 1 == 0:\\n        save_model(args, model, optimizer)\\n\\n    writer.add_scalar(\"Loss/train\", loss_epoch / len(train_loader), epoch)\\n    writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\\n    print(\\n        f\"Epoch [{epoch}/{args.epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t lr: {round(lr, 5)}\"\\n    )\\n    args.current_epoch += 1\\n\\n## end training\\nsave_model(args, model, optimizer)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "77BXUR9_4hNc"
      },
      "source": [
        "## Download last checkpoint to local drive (replace `100` with `args.epochs`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d7eHATk04Sgu",
        "colab": {}
      },
      "source": [
        "#from google.colab import files\n",
        "#files.download('./logs/checkpoint_'+ str(args.epochs) +'.tar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tAQpjiuJy61N"
      },
      "source": [
        "# Part 2:\n",
        "## Linear evaluation using logistic regression, using weights from frozen, pre-trained SimCLR model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "24wrzMP2vYcV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kFyS9RvpuCuC",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import argparse\n",
        "\n",
        "from experiment import ex\n",
        "from model import load_model\n",
        "from utils import post_config_hook\n",
        "\n",
        "#from modules import LogisticRegression\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAaCZX7__VXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_ts_road_map(road_map1, road_map2):\n",
        "    tp = (road_map1 * road_map2).sum()\n",
        "\n",
        "    return tp * 1.0 / (road_map1.sum() + road_map2.sum() - tp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pZRtPBCLvgqz",
        "colab": {}
      },
      "source": [
        "def train(args, loader, simclr_model, model,criterion, optimizer):\n",
        "    loss_epoch = 0\n",
        "    accuracy_epoch = 0\n",
        "    model.to(args.device)\n",
        "    simclr_model.train()\n",
        "    model.train()\n",
        "    #with torch.no_grad():\n",
        "    for step, (x, y) in enumerate(loader):\n",
        "        #print(x.shape)\n",
        "        #print(y.shape)\n",
        "        y = y.type(torch.float)\n",
        "        y = y.reshape(-1, 640000)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x = x.to(args.device)\n",
        "        y = y.to(args.device)\n",
        "        \n",
        "\n",
        "        # get encoding\n",
        "        #with torch.no_grad():\n",
        "        h, z = simclr_model(x)\n",
        "            #h.requires_grad = True\n",
        "            #k = model1(h)\n",
        "            #h = 512\n",
        "            #z = 64\n",
        "            #print(h.shape)\n",
        "            #print(z.shape)\n",
        "        #loss =0\n",
        "        #for i,j in zip(h,y):\n",
        "        output = model(h)\n",
        "            #output.requires_grad = True\n",
        "        loss = criterion(output, y)\n",
        "            #loss.requires_grad = True\n",
        "\n",
        "        #predicted = output.argmax(1)\n",
        "        #acc = (predicted == y).sum().item() / y.size(0)\n",
        "        iou = compute_ts_road_map(output,y)\n",
        "        accuracy_epoch += iou\n",
        "        #accuracy_epoch += acc\n",
        "\n",
        "        loss.backward()\n",
        "        #output.grad.zero()\n",
        "        #with torch.no_grad():\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_epoch += loss.item()\n",
        "        if step % 1 == 0:\n",
        "            print(f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {iou}\")\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return loss_epoch, accuracy_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "skBYAPb2uKB5",
        "colab": {}
      },
      "source": [
        "def test(args, loader, simclr_model, model, criterion, optimizer):\n",
        "    loss_epoch = 0\n",
        "    accuracy_epoch = 0\n",
        "    model.to(args.device)\n",
        "    simclr_model.eval()\n",
        "    model.eval()\n",
        "    for step, (x, y) in enumerate(loader):\n",
        "        model.zero_grad()\n",
        "        y = y.type(torch.float)\n",
        "        y = y.reshape(-1, 640000)\n",
        "\n",
        "        x = x.to(args.device)\n",
        "        y = y.to(args.device)\n",
        "\n",
        "        # get encoding\n",
        "        with torch.no_grad():\n",
        "            h, z = simclr_model(x)\n",
        "            # h = 512\n",
        "            # z = 64\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(h)\n",
        "            loss = criterion(output, y)\n",
        "\n",
        "            #predicted = output.argmax(1)\n",
        "            #acc = (predicted == y).sum().item() / y.size(0)\n",
        "            iou = compute_ts_road_map(output,y)\n",
        "            accuracy_epoch += iou\n",
        "            #accuracy_epoch += acc\n",
        "\n",
        "            loss_epoch += loss.item()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    return loss_epoch, accuracy_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OJk4-nc-vkF0",
        "outputId": "901d258e-dfca-4d92-a099-6f08db8c3a8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from pprint import pprint\n",
        "from utils.yaml_config_hook import yaml_config_hook\n",
        "\n",
        "config = yaml_config_hook(\"./config/config.yaml\")\n",
        "pprint(config)\n",
        "args = argparse.Namespace(**config)\n",
        "\n",
        "if use_tpu:\n",
        "  args.device = dev\n",
        "else:\n",
        "  args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 128,\n",
            " 'dataset': 'STL10',\n",
            " 'epoch_num': 100,\n",
            " 'epochs': 100,\n",
            " 'fp16': False,\n",
            " 'fp16_opt_level': 'O2',\n",
            " 'logistic_batch_size': 256,\n",
            " 'logistic_epochs': 100,\n",
            " 'model_path': 'logs/0',\n",
            " 'normalize': True,\n",
            " 'optimizer': 'Adam',\n",
            " 'projection_dim': 64,\n",
            " 'resnet': 'resnet50',\n",
            " 'seed': 42,\n",
            " 'start_epoch': 0,\n",
            " 'temperature': 0.5,\n",
            " 'weight_decay': 1e-06,\n",
            " 'workers': 16}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_7cSwhu55KJc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "dccd5e34-e86f-41df-ea65-6e1eab2d77b1"
      },
      "source": [
        "args.batch_size = 2\n",
        "args.resnet = \"resnet18\"\n",
        "args.model_path = \"logs/simclrPretext\"\n",
        "args.epochs = 1\n",
        "args.epoch_num = 1\n",
        "args.dataset = 'road'\n",
        "args.logistic_epochs =2\n",
        "args.logistic_batch_size = 2\n",
        "args.out_dir = \"logs/train\"\n",
        "#args.optimizer = \"LARS\"\n",
        "pprint(vars(args))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 2,\n",
            " 'dataset': 'road',\n",
            " 'device': device(type='cuda'),\n",
            " 'epoch_num': 1,\n",
            " 'epochs': 1,\n",
            " 'fp16': False,\n",
            " 'fp16_opt_level': 'O2',\n",
            " 'logistic_batch_size': 2,\n",
            " 'logistic_epochs': 2,\n",
            " 'model_path': 'logs/simclrPretext',\n",
            " 'normalize': True,\n",
            " 'optimizer': 'Adam',\n",
            " 'out_dir': 'logs/train',\n",
            " 'projection_dim': 64,\n",
            " 'resnet': 'resnet18',\n",
            " 'seed': 42,\n",
            " 'start_epoch': 0,\n",
            " 'temperature': 0.5,\n",
            " 'weight_decay': 1e-06,\n",
            " 'workers': 16}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z0UzMi9_VXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The scenes from 106 - 133 are labeled\n",
        "# You should devide the labeled_scene_index into two subsets (training and validation)\n",
        "labeled_scene_index = np.arange(106, 120)\n",
        "\n",
        "## validation scene index.\n",
        "validation_scene_index = np.arange(120, 134)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMW7gzem_VXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform = torchvision.transforms.Compose(\n",
        "            [\n",
        "                #torchvision.transforms.RandomResizedCrop(size=(256,306)),\n",
        "                torchvision.transforms.ToTensor(),\n",
        "            ]\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rH6L2VL_VXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from data_helper import SimclrLabeledDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GWRuVrZZ5Vm1"
      },
      "source": [
        "### Load dataset into train/test dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iPGuFjLW5PF9",
        "colab": {}
      },
      "source": [
        "root = \"./datasets\"\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "if args.dataset == \"STL10\":\n",
        "    train_dataset = torchvision.datasets.STL10(\n",
        "        root, split=\"train\", download=True, transform=torchvision.transforms.ToTensor()\n",
        "    )\n",
        "    test_dataset = torchvision.datasets.STL10(\n",
        "        root, split=\"test\", download=True, transform=torchvision.transforms.ToTensor()\n",
        "    )\n",
        "elif args.dataset == \"CIFAR10\":\n",
        "    train_dataset = torchvision.datasets.CIFAR10(\n",
        "        root, train=True, download=True, transform=transform\n",
        "    )\n",
        "    test_dataset = torchvision.datasets.CIFAR10(\n",
        "        root, train=False, download=True, transform=transform\n",
        "    )\n",
        "elif args.dataset == \"road\":\n",
        "    train_dataset = SimclrLabeledDataset(image_folder=image_folder, \n",
        "      scene_index = labeled_scene_index, annotation_file=annotation_csv,transform = train_transform )\n",
        "    test_dataset = SimclrLabeledDataset(image_folder=image_folder, \n",
        "      scene_index = validation_scene_index, annotation_file=annotation_csv, transform = train_transform)\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=args.logistic_batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=args.workers,\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=args.logistic_batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        "    num_workers=args.workers,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fd7rVuX_VXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hVlJDv9_VXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#torch.cuda.get_device_properties(args.device).total_memory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TmwXqVBH5ZX6"
      },
      "source": [
        "### Load SimCLR model and load model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RTVnvx2a5QnX",
        "colab": {}
      },
      "source": [
        "simclr_model, _, _ = load_model(args, train_loader, reload_model=True)\n",
        "simclr_model = simclr_model.to(args.device)\n",
        "#simclr_model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVhBZ05N_VXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCWzVhgy_VXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ASPP(nn.Module):\n",
        "\n",
        "    def __init__(self, C, depth, num_classes, conv=nn.Conv2d, norm=nn.BatchNorm2d, momentum=0.0003, mult=1):\n",
        "        super(ASPP, self).__init__()\n",
        "        self._C = C\n",
        "        self._depth = depth\n",
        "        self._num_classes = num_classes\n",
        "\n",
        "        self.global_pooling = nn.AdaptiveAvgPool2d(1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.aspp1 = conv(C, depth, kernel_size=1, stride=1, bias=False)\n",
        "        self.aspp2 = conv(C, depth, kernel_size=3, stride=1,\n",
        "                               dilation=int(6*mult), padding=int(6*mult),\n",
        "                               bias=False)\n",
        "        self.aspp3 = conv(C, depth, kernel_size=3, stride=1,\n",
        "                               dilation=int(12*mult), padding=int(12*mult),\n",
        "                               bias=False)\n",
        "        self.aspp4 = conv(C, depth, kernel_size=3, stride=1,\n",
        "                               dilation=int(18*mult), padding=int(18*mult),\n",
        "                               bias=False)\n",
        "        self.aspp5 = conv(C, depth, kernel_size=1, stride=1, bias=False)\n",
        "        self.aspp1_bn = norm(depth, momentum)\n",
        "        self.aspp2_bn = norm(depth, momentum)\n",
        "        self.aspp3_bn = norm(depth, momentum)\n",
        "        self.aspp4_bn = norm(depth, momentum)\n",
        "        self.aspp5_bn = norm(depth, momentum)\n",
        "        self.conv2 = conv(depth * 5, depth, kernel_size=1, stride=1,\n",
        "                               bias=False)\n",
        "        self.bn2 = norm(depth, momentum)\n",
        "        self.conv3 = nn.Conv2d(depth, num_classes, kernel_size=1, stride=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.aspp1(x)\n",
        "        #print(x1.shape)\n",
        "        x1 = self.aspp1_bn(x1)\n",
        "        #print(x1.shape)\n",
        "        x1 = self.relu(x1)\n",
        "        #print(x1.shape)\n",
        "        x2 = self.aspp2(x)\n",
        "        #print(x2.shape)\n",
        "        x2 = self.aspp2_bn(x2)\n",
        "        #print(x2.shape)\n",
        "        x2 = self.relu(x2)\n",
        "        #print(x2.shape)\n",
        "        x3 = self.aspp3(x)\n",
        "        #print(x3.shape)\n",
        "        x3 = self.aspp3_bn(x3)\n",
        "        #print(x3.shape)\n",
        "        x3 = self.relu(x3)\n",
        "        #print(x3.shape)\n",
        "        x4 = self.aspp4(x)\n",
        "        #print(x4.shape)\n",
        "        x4 = self.aspp4_bn(x4)\n",
        "        #print(x4.shape)\n",
        "        x4 = self.relu(x4)\n",
        "        #print(x4.shape)\n",
        "        x5 = self.global_pooling(x)\n",
        "        #print(x5.shape)\n",
        "        x5 = self.aspp5(x5)\n",
        "        #print(x5.shape)\n",
        "        x5 = self.aspp5_bn(x5)\n",
        "        #print(x5.shape)\n",
        "        x5 = self.relu(x5)\n",
        "        x5 = nn.Upsample((x.shape[2], x.shape[3]), mode='bilinear',\n",
        "                         align_corners=True)(x5)\n",
        "        #print(x5.shape)\n",
        "        x = torch.cat((x1, x2, x3, x4, x5), 1)\n",
        "        #print(x.shape)\n",
        "        x = self.conv2(x)\n",
        "        #print(x.shape)\n",
        "        x = self.bn2(x)\n",
        "        #print(x.shape)\n",
        "        x = self.relu(x)\n",
        "        #print(x.shape)\n",
        "        x = self.conv3(x)\n",
        "        #print(x.shape)\n",
        "        #print(\"*******\")\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXn8V40f_VXz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "8dcb7d6e-01d8-413d-febc-960993d2d39e"
      },
      "source": [
        "pprint(vars(args))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 2,\n",
            " 'dataset': 'road',\n",
            " 'device': device(type='cuda'),\n",
            " 'epoch_num': 1,\n",
            " 'epochs': 1,\n",
            " 'fp16': False,\n",
            " 'fp16_opt_level': 'O2',\n",
            " 'logistic_batch_size': 2,\n",
            " 'logistic_epochs': 2,\n",
            " 'model_path': 'logs/simclrPretext',\n",
            " 'normalize': True,\n",
            " 'optimizer': 'Adam',\n",
            " 'out_dir': 'logs/train',\n",
            " 'projection_dim': 64,\n",
            " 'resnet': 'resnet18',\n",
            " 'seed': 42,\n",
            " 'start_epoch': 0,\n",
            " 'temperature': 0.5,\n",
            " 'weight_decay': 1e-06,\n",
            " 'workers': 16}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWDU3zKZ_VX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(list(list(simclr_model.children())[0].children())[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qt1A7OC_VX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(simclr_model.module.encoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1geqF07_VX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model1 = nn.Sequential(simclr_model.module.encoder.conv1, simclr_model.module.encoder.bn1, simclr_model.module.encoder.relu,\n",
        "                                     #simclr_model.module.encoder.maxpool, simclr_model.module.encoder.layer1, simclr_model.module.encoder.layer2,\n",
        "                                    #simclr_model.module.encoder.layer3, simclr_model.module.encoder.layer4)\n",
        "\n",
        "#model1 = nn.DataParallel(model1)\n",
        "#model1 = model1.to(args.device)\n",
        "#simclr_model.eval()\n",
        "#model1.eval()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3dm_CfZ_VX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(model1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbAxCsCw_VX8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a67db6b-1346-4278-cca9-6bb0acb28126"
      },
      "source": [
        "print(simclr_model)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SimCLR(\n",
            "  (encoder): ResNet(\n",
            "    (conv1): Conv2d(18, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Identity()\n",
            "  )\n",
            "  (projector): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=64, bias=False)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uLmknQG_VX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Reshape(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Reshape, self).__init__()\n",
        "        #self.shape = [256,512,1,1]\n",
        "    def forward(self, x):\n",
        "        return x.view(64,512,2,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOKsG0U9_VYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Reshape1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Reshape1, self).__init__()\n",
        "        #self.shape = [256,512,1,1]\n",
        "    def forward(self, x):\n",
        "        return x.view(-1,65536)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HZoABGRr5Q8_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "addb16c3-b7c8-4aa7-a05c-fabe20a3fe59"
      },
      "source": [
        "n_classes = 640000\n",
        "model = torch.nn.Sequential(nn.Linear(512,512*8*8*2),\n",
        "                            Reshape(),\n",
        "            ASPP(simclr_model.n_features, 64, 512),\n",
        "                            Reshape1(),\n",
        "            torch.nn.Linear(in_features=512*64*2,\n",
        "                            out_features=512),\n",
        "            torch.nn.Linear(in_features=512,\n",
        "                            out_features=640000),\n",
        "            torch.nn.Sigmoid())\n",
        "\n",
        "model = nn.DataParallel(model)\n",
        "print(model)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DataParallel(\n",
            "  (module): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=65536, bias=True)\n",
            "    (1): Reshape()\n",
            "    (2): ASPP(\n",
            "      (global_pooling): AdaptiveAvgPool2d(output_size=1)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (aspp1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (aspp2): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n",
            "      (aspp3): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
            "      (aspp4): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n",
            "      (aspp5): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (aspp1_bn): BatchNorm2d(64, eps=0.0003, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (aspp2_bn): BatchNorm2d(64, eps=0.0003, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (aspp3_bn): BatchNorm2d(64, eps=0.0003, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (aspp4_bn): BatchNorm2d(64, eps=0.0003, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (aspp5_bn): BatchNorm2d(64, eps=0.0003, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=0.0003, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (3): Reshape1()\n",
            "    (4): Linear(in_features=65536, out_features=512, bias=True)\n",
            "    (5): Linear(in_features=512, out_features=640000, bias=True)\n",
            "    (6): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T694n_HQ5Tad",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "criterion = torch.nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vLaebM9Qvztx",
        "outputId": "f96019a3-c01f-4d5e-8ef1-b63436b035e1",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "args.current_epoch = 0\n",
        "for epoch in range(args.logistic_epochs):\n",
        "    loss_epoch, accuracy_epoch = train(args, train_loader, simclr_model, model, criterion, optimizer)\n",
        "    save_model(args, model, optimizer)\n",
        "    print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n",
        "    args.current_epoch += 1\n",
        "    torch.cuda.empty_cache()\n",
        "    # final validation\n",
        "    loss_epoch, accuracy_epoch = test(args, test_loader, simclr_model, model, criterion, optimizer)\n",
        "    print(f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\")\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step [0/882]\t Loss: 0.6956052184104919\t Accuracy: 0.29510053992271423\n",
            "Step [1/882]\t Loss: 1.4634462594985962\t Accuracy: 0.25879451632499695\n",
            "Step [2/882]\t Loss: 0.7732462286949158\t Accuracy: 0.29887518286705017\n",
            "Step [3/882]\t Loss: 0.7790882587432861\t Accuracy: 0.3199174702167511\n",
            "Step [4/882]\t Loss: 0.7067425847053528\t Accuracy: 0.3051649034023285\n",
            "Step [5/882]\t Loss: 0.7312831282615662\t Accuracy: 0.2668009102344513\n",
            "Step [6/882]\t Loss: 0.7312071919441223\t Accuracy: 0.2977937161922455\n",
            "Step [7/882]\t Loss: 0.6772157549858093\t Accuracy: 0.2776571214199066\n",
            "Step [8/882]\t Loss: 0.6735633611679077\t Accuracy: 0.27266955375671387\n",
            "Step [9/882]\t Loss: 0.6786260008811951\t Accuracy: 0.3611682653427124\n",
            "Step [10/882]\t Loss: 0.6484636664390564\t Accuracy: 0.28911903500556946\n",
            "Step [11/882]\t Loss: 0.6241143345832825\t Accuracy: 0.3188091218471527\n",
            "Step [12/882]\t Loss: 0.5666171908378601\t Accuracy: 0.3927516043186188\n",
            "Step [13/882]\t Loss: 0.5950679183006287\t Accuracy: 0.4074297845363617\n",
            "Step [14/882]\t Loss: 0.5750625729560852\t Accuracy: 0.3713884651660919\n",
            "Step [15/882]\t Loss: 0.5033147931098938\t Accuracy: 0.39053666591644287\n",
            "Step [16/882]\t Loss: 0.3652387857437134\t Accuracy: 0.5038820505142212\n",
            "Step [17/882]\t Loss: 0.3756369650363922\t Accuracy: 0.5307908058166504\n",
            "Step [18/882]\t Loss: 0.3206016421318054\t Accuracy: 0.6110891103744507\n",
            "Step [19/882]\t Loss: 0.3734455406665802\t Accuracy: 0.6361799240112305\n",
            "Step [20/882]\t Loss: 0.41045042872428894\t Accuracy: 0.6456714272499084\n",
            "Step [21/882]\t Loss: 0.4937273859977722\t Accuracy: 0.6068584322929382\n",
            "Step [22/882]\t Loss: 0.39487382769584656\t Accuracy: 0.5987311005592346\n",
            "Step [23/882]\t Loss: 0.2786779999732971\t Accuracy: 0.5836817622184753\n",
            "Step [24/882]\t Loss: 0.4630453884601593\t Accuracy: 0.4701779782772064\n",
            "Step [25/882]\t Loss: 0.4654652178287506\t Accuracy: 0.44749584794044495\n",
            "Step [26/882]\t Loss: 0.5230575203895569\t Accuracy: 0.3769291639328003\n",
            "Step [27/882]\t Loss: 0.6091743111610413\t Accuracy: 0.4257078170776367\n",
            "Step [28/882]\t Loss: 0.417376846075058\t Accuracy: 0.565216064453125\n",
            "Step [29/882]\t Loss: 0.4682418704032898\t Accuracy: 0.6023612022399902\n",
            "Step [30/882]\t Loss: 0.3302668035030365\t Accuracy: 0.6506315469741821\n",
            "Step [31/882]\t Loss: 0.9006462693214417\t Accuracy: 0.35025179386138916\n",
            "Step [32/882]\t Loss: 0.4385635256767273\t Accuracy: 0.465064138174057\n",
            "Step [33/882]\t Loss: 0.4447205066680908\t Accuracy: 0.4589095413684845\n",
            "Step [34/882]\t Loss: 0.342816025018692\t Accuracy: 0.5206903219223022\n",
            "Step [35/882]\t Loss: 0.4573151767253876\t Accuracy: 0.5894372463226318\n",
            "Step [36/882]\t Loss: 0.3469853401184082\t Accuracy: 0.6589145064353943\n",
            "Step [37/882]\t Loss: 0.4200856685638428\t Accuracy: 0.6275011897087097\n",
            "Step [38/882]\t Loss: 0.15569977462291718\t Accuracy: 0.745500922203064\n",
            "Step [39/882]\t Loss: 0.22899067401885986\t Accuracy: 0.7330162525177002\n",
            "Step [40/882]\t Loss: 0.6125768423080444\t Accuracy: 0.6318404674530029\n",
            "Step [41/882]\t Loss: 0.14864541590213776\t Accuracy: 0.7859891653060913\n",
            "Step [42/882]\t Loss: 0.3981890082359314\t Accuracy: 0.5776534676551819\n",
            "Step [43/882]\t Loss: 0.5584673285484314\t Accuracy: 0.5184697508811951\n",
            "Step [44/882]\t Loss: 0.8066141605377197\t Accuracy: 0.37026986479759216\n",
            "Step [45/882]\t Loss: 0.400147408246994\t Accuracy: 0.49833545088768005\n",
            "Step [46/882]\t Loss: 0.6053961515426636\t Accuracy: 0.35348495841026306\n",
            "Step [47/882]\t Loss: 0.5460344552993774\t Accuracy: 0.3961021900177002\n",
            "Step [48/882]\t Loss: 0.41279953718185425\t Accuracy: 0.4820549488067627\n",
            "Step [49/882]\t Loss: 0.49792155623435974\t Accuracy: 0.47110113501548767\n",
            "Step [50/882]\t Loss: 0.4206925630569458\t Accuracy: 0.5680245757102966\n",
            "Step [51/882]\t Loss: 0.31781864166259766\t Accuracy: 0.6341443061828613\n",
            "Step [52/882]\t Loss: 0.3415759801864624\t Accuracy: 0.6529437303543091\n",
            "Step [53/882]\t Loss: 0.7148095369338989\t Accuracy: 0.495292603969574\n",
            "Step [54/882]\t Loss: 0.6048091650009155\t Accuracy: 0.5179589986801147\n",
            "Step [55/882]\t Loss: 0.4024987816810608\t Accuracy: 0.6254692077636719\n",
            "Step [56/882]\t Loss: 0.2722519040107727\t Accuracy: 0.6297544240951538\n",
            "Step [57/882]\t Loss: 0.24676793813705444\t Accuracy: 0.6396397352218628\n",
            "Step [58/882]\t Loss: 0.38907477259635925\t Accuracy: 0.5674792528152466\n",
            "Step [59/882]\t Loss: 0.34021425247192383\t Accuracy: 0.5796756148338318\n",
            "Step [60/882]\t Loss: 0.40677598118782043\t Accuracy: 0.5511763095855713\n",
            "Step [61/882]\t Loss: 0.45826491713523865\t Accuracy: 0.5268781781196594\n",
            "Step [62/882]\t Loss: 0.5580936670303345\t Accuracy: 0.4314110279083252\n",
            "Step [63/882]\t Loss: 0.41885271668434143\t Accuracy: 0.5352638959884644\n",
            "Step [64/882]\t Loss: 0.3727184534072876\t Accuracy: 0.5216289162635803\n",
            "Step [65/882]\t Loss: 0.3420563042163849\t Accuracy: 0.5372030735015869\n",
            "Step [66/882]\t Loss: 0.2763522267341614\t Accuracy: 0.5908169746398926\n",
            "Step [67/882]\t Loss: 0.2772621512413025\t Accuracy: 0.6312283277511597\n",
            "Step [68/882]\t Loss: 0.6154347658157349\t Accuracy: 0.47191593050956726\n",
            "Step [69/882]\t Loss: 0.7331907153129578\t Accuracy: 0.5009387135505676\n",
            "Step [70/882]\t Loss: 0.6793625950813293\t Accuracy: 0.46927154064178467\n",
            "Step [71/882]\t Loss: 0.31747540831565857\t Accuracy: 0.608280599117279\n",
            "Step [72/882]\t Loss: 0.41025644540786743\t Accuracy: 0.5584213733673096\n",
            "Step [73/882]\t Loss: 0.41991469264030457\t Accuracy: 0.5296450853347778\n",
            "Step [74/882]\t Loss: 0.619675874710083\t Accuracy: 0.36639782786369324\n",
            "Step [75/882]\t Loss: 0.48239657282829285\t Accuracy: 0.46528545022010803\n",
            "Step [76/882]\t Loss: 0.3759802281856537\t Accuracy: 0.4569738209247589\n",
            "Step [77/882]\t Loss: 0.3721083104610443\t Accuracy: 0.5307502746582031\n",
            "Step [78/882]\t Loss: 0.49128222465515137\t Accuracy: 0.4671677052974701\n",
            "Step [79/882]\t Loss: 0.27863168716430664\t Accuracy: 0.6328434944152832\n",
            "Step [80/882]\t Loss: 0.5947093367576599\t Accuracy: 0.5038924217224121\n",
            "Step [81/882]\t Loss: 0.5555102229118347\t Accuracy: 0.5159834027290344\n",
            "Step [82/882]\t Loss: 0.4264039099216461\t Accuracy: 0.5412825345993042\n",
            "Step [83/882]\t Loss: 0.3695017397403717\t Accuracy: 0.6247759461402893\n",
            "Step [84/882]\t Loss: 0.7575837969779968\t Accuracy: 0.36582621932029724\n",
            "Step [85/882]\t Loss: 0.24181491136550903\t Accuracy: 0.6299583911895752\n",
            "Step [86/882]\t Loss: 0.49460628628730774\t Accuracy: 0.4553222060203552\n",
            "Step [87/882]\t Loss: 0.45481306314468384\t Accuracy: 0.5034376978874207\n",
            "Step [88/882]\t Loss: 0.5004819631576538\t Accuracy: 0.49832847714424133\n",
            "Step [89/882]\t Loss: 0.5133607387542725\t Accuracy: 0.4077287018299103\n",
            "Step [90/882]\t Loss: 0.6106211543083191\t Accuracy: 0.38883382081985474\n",
            "Step [91/882]\t Loss: 0.47907596826553345\t Accuracy: 0.3906514346599579\n",
            "Step [92/882]\t Loss: 0.4490806460380554\t Accuracy: 0.3733406364917755\n",
            "Step [93/882]\t Loss: 0.4048786163330078\t Accuracy: 0.4139145314693451\n",
            "Step [94/882]\t Loss: 0.5410341620445251\t Accuracy: 0.42261257767677307\n",
            "Step [95/882]\t Loss: 0.48209598660469055\t Accuracy: 0.4700833559036255\n",
            "Step [96/882]\t Loss: 0.3189021944999695\t Accuracy: 0.5443057417869568\n",
            "Step [97/882]\t Loss: 0.2443111687898636\t Accuracy: 0.5859498977661133\n",
            "Step [98/882]\t Loss: 0.4818510115146637\t Accuracy: 0.5316036343574524\n",
            "Step [99/882]\t Loss: 0.24433864653110504\t Accuracy: 0.6269316673278809\n",
            "Step [100/882]\t Loss: 0.34616267681121826\t Accuracy: 0.6134790778160095\n",
            "Step [101/882]\t Loss: 0.45005711913108826\t Accuracy: 0.6141129732131958\n",
            "Step [102/882]\t Loss: 0.20169243216514587\t Accuracy: 0.7062395215034485\n",
            "Step [103/882]\t Loss: 0.3427933156490326\t Accuracy: 0.6470621228218079\n",
            "Step [104/882]\t Loss: 0.29562824964523315\t Accuracy: 0.6721183061599731\n",
            "Step [105/882]\t Loss: 0.7012505531311035\t Accuracy: 0.4827142655849457\n",
            "Step [106/882]\t Loss: 0.5741513967514038\t Accuracy: 0.5069161057472229\n",
            "Step [107/882]\t Loss: 0.45369237661361694\t Accuracy: 0.5198298096656799\n",
            "Step [108/882]\t Loss: 0.508984386920929\t Accuracy: 0.4560210406780243\n",
            "Step [109/882]\t Loss: 0.28258848190307617\t Accuracy: 0.5745086073875427\n",
            "Step [110/882]\t Loss: 0.4051259160041809\t Accuracy: 0.5301123857498169\n",
            "Step [111/882]\t Loss: 0.4838958978652954\t Accuracy: 0.43403759598731995\n",
            "Step [112/882]\t Loss: 0.496724396944046\t Accuracy: 0.35223299264907837\n",
            "Step [113/882]\t Loss: 0.4223628342151642\t Accuracy: 0.5463182926177979\n",
            "Step [114/882]\t Loss: 0.4241839349269867\t Accuracy: 0.47379201650619507\n",
            "Step [115/882]\t Loss: 0.3104899227619171\t Accuracy: 0.5792527198791504\n",
            "Step [116/882]\t Loss: 0.49084705114364624\t Accuracy: 0.4677080810070038\n",
            "Step [117/882]\t Loss: 0.3797699213027954\t Accuracy: 0.5000129342079163\n",
            "Step [118/882]\t Loss: 0.22201469540596008\t Accuracy: 0.6240360736846924\n",
            "Step [119/882]\t Loss: 0.20293164253234863\t Accuracy: 0.6559116840362549\n",
            "Step [120/882]\t Loss: 0.40948107838630676\t Accuracy: 0.5094136595726013\n",
            "Step [121/882]\t Loss: 0.19142861664295197\t Accuracy: 0.6855005025863647\n",
            "Step [122/882]\t Loss: 0.6300880908966064\t Accuracy: 0.5093474984169006\n",
            "Step [123/882]\t Loss: 0.42073988914489746\t Accuracy: 0.573371946811676\n",
            "Step [124/882]\t Loss: 0.5247672200202942\t Accuracy: 0.5534737706184387\n",
            "Step [125/882]\t Loss: 0.48218676447868347\t Accuracy: 0.5091742277145386\n",
            "Step [126/882]\t Loss: 0.45941540598869324\t Accuracy: 0.54912269115448\n",
            "Step [127/882]\t Loss: 0.43463173508644104\t Accuracy: 0.5309447646141052\n",
            "Step [128/882]\t Loss: 0.3887249529361725\t Accuracy: 0.5009485483169556\n",
            "Step [129/882]\t Loss: 0.46739593148231506\t Accuracy: 0.4322417378425598\n",
            "Step [130/882]\t Loss: 0.45878133177757263\t Accuracy: 0.4322313666343689\n",
            "Step [131/882]\t Loss: 0.48873183131217957\t Accuracy: 0.4864177107810974\n",
            "Step [132/882]\t Loss: 0.28805556893348694\t Accuracy: 0.542654275894165\n",
            "Step [133/882]\t Loss: 0.3076307773590088\t Accuracy: 0.5575857758522034\n",
            "Step [134/882]\t Loss: 0.3278391659259796\t Accuracy: 0.5816897749900818\n",
            "Step [135/882]\t Loss: 0.5100388526916504\t Accuracy: 0.48282352089881897\n",
            "Step [136/882]\t Loss: 0.3733900487422943\t Accuracy: 0.6025339365005493\n",
            "Step [137/882]\t Loss: 0.5487427711486816\t Accuracy: 0.487994521856308\n",
            "Step [138/882]\t Loss: 0.3689398467540741\t Accuracy: 0.5422752499580383\n",
            "Step [139/882]\t Loss: 0.4147937297821045\t Accuracy: 0.6094486117362976\n",
            "Step [140/882]\t Loss: 0.28962650895118713\t Accuracy: 0.6439101696014404\n",
            "Step [141/882]\t Loss: 0.23247824609279633\t Accuracy: 0.6650258302688599\n",
            "Step [142/882]\t Loss: 0.3089450001716614\t Accuracy: 0.6228619813919067\n",
            "Step [143/882]\t Loss: 0.5544258952140808\t Accuracy: 0.5477873086929321\n",
            "Step [144/882]\t Loss: 0.37330564856529236\t Accuracy: 0.5911847352981567\n",
            "Step [145/882]\t Loss: 0.5990411043167114\t Accuracy: 0.4527541995048523\n",
            "Step [146/882]\t Loss: 0.5423635244369507\t Accuracy: 0.45339685678482056\n",
            "Step [147/882]\t Loss: 0.5301733016967773\t Accuracy: 0.5051647424697876\n",
            "Step [148/882]\t Loss: 0.3944779634475708\t Accuracy: 0.5043673515319824\n",
            "Step [149/882]\t Loss: 0.5323413014411926\t Accuracy: 0.31649139523506165\n",
            "Step [150/882]\t Loss: 0.5671724081039429\t Accuracy: 0.40748804807662964\n",
            "Step [151/882]\t Loss: 0.4224790930747986\t Accuracy: 0.41260942816734314\n",
            "Step [152/882]\t Loss: 0.3477872312068939\t Accuracy: 0.5114721059799194\n",
            "Step [153/882]\t Loss: 0.4719570279121399\t Accuracy: 0.44987863302230835\n",
            "Step [154/882]\t Loss: 0.29167506098747253\t Accuracy: 0.5844159722328186\n",
            "Step [155/882]\t Loss: 0.25075891613960266\t Accuracy: 0.6175805330276489\n",
            "Step [156/882]\t Loss: 0.26268452405929565\t Accuracy: 0.6476656794548035\n",
            "Step [157/882]\t Loss: 0.23841151595115662\t Accuracy: 0.6779904365539551\n",
            "Step [158/882]\t Loss: 0.24486196041107178\t Accuracy: 0.6904404759407043\n",
            "Step [159/882]\t Loss: 0.6588444709777832\t Accuracy: 0.5095921158790588\n",
            "Step [160/882]\t Loss: 0.3935296833515167\t Accuracy: 0.6644850969314575\n",
            "Step [161/882]\t Loss: 0.7941386699676514\t Accuracy: 0.4834534525871277\n",
            "Step [162/882]\t Loss: 0.4650760591030121\t Accuracy: 0.6035140752792358\n",
            "Step [163/882]\t Loss: 0.4534694254398346\t Accuracy: 0.5789728760719299\n",
            "Step [164/882]\t Loss: 0.23627349734306335\t Accuracy: 0.6341702342033386\n",
            "Step [165/882]\t Loss: 0.42327260971069336\t Accuracy: 0.47200807929039\n",
            "Step [166/882]\t Loss: 0.404983252286911\t Accuracy: 0.4678724408149719\n",
            "Step [167/882]\t Loss: 0.3015702962875366\t Accuracy: 0.5439141392707825\n",
            "Step [168/882]\t Loss: 0.3691498339176178\t Accuracy: 0.5420604348182678\n",
            "Step [169/882]\t Loss: 0.28199270367622375\t Accuracy: 0.5949189066886902\n",
            "Step [170/882]\t Loss: 0.25326189398765564\t Accuracy: 0.6412627696990967\n",
            "Step [171/882]\t Loss: 0.5366197824478149\t Accuracy: 0.5692980885505676\n",
            "Step [172/882]\t Loss: 0.33672159910202026\t Accuracy: 0.6309331059455872\n",
            "Step [173/882]\t Loss: 0.2658238112926483\t Accuracy: 0.6686261892318726\n",
            "Step [174/882]\t Loss: 0.5409371852874756\t Accuracy: 0.5873941779136658\n",
            "Step [175/882]\t Loss: 0.16086772084236145\t Accuracy: 0.736585259437561\n",
            "Step [176/882]\t Loss: 0.4453502893447876\t Accuracy: 0.5624839067459106\n",
            "Step [177/882]\t Loss: 0.4535651206970215\t Accuracy: 0.5537590384483337\n",
            "Step [178/882]\t Loss: 0.48654744029045105\t Accuracy: 0.5986728668212891\n",
            "Step [179/882]\t Loss: 0.6227570176124573\t Accuracy: 0.4555304944515228\n",
            "Step [180/882]\t Loss: 0.4621056914329529\t Accuracy: 0.4949716329574585\n",
            "Step [181/882]\t Loss: 0.41843748092651367\t Accuracy: 0.4956289529800415\n",
            "Step [182/882]\t Loss: 0.3395029604434967\t Accuracy: 0.5565505623817444\n",
            "Step [183/882]\t Loss: 0.3155680000782013\t Accuracy: 0.5552639961242676\n",
            "Step [184/882]\t Loss: 0.36906611919403076\t Accuracy: 0.5231636762619019\n",
            "Step [185/882]\t Loss: 0.4602136015892029\t Accuracy: 0.5123302936553955\n",
            "Step [186/882]\t Loss: 0.3969140946865082\t Accuracy: 0.4567473828792572\n",
            "Step [187/882]\t Loss: 0.30179551243782043\t Accuracy: 0.567093551158905\n",
            "Step [188/882]\t Loss: 0.523311197757721\t Accuracy: 0.5148645639419556\n",
            "Step [189/882]\t Loss: 0.37132328748703003\t Accuracy: 0.5574748516082764\n",
            "Step [190/882]\t Loss: 0.25321221351623535\t Accuracy: 0.6136478185653687\n",
            "Step [191/882]\t Loss: 0.41560837626457214\t Accuracy: 0.56280118227005\n",
            "Step [192/882]\t Loss: 0.3164779841899872\t Accuracy: 0.5992374420166016\n",
            "Step [193/882]\t Loss: 0.24355511367321014\t Accuracy: 0.6558716893196106\n",
            "Step [194/882]\t Loss: 0.34169432520866394\t Accuracy: 0.6250059604644775\n",
            "Step [195/882]\t Loss: 0.17359143495559692\t Accuracy: 0.7124317288398743\n",
            "Step [196/882]\t Loss: 0.19383874535560608\t Accuracy: 0.7038142681121826\n",
            "Step [197/882]\t Loss: 0.19161547720432281\t Accuracy: 0.7319605946540833\n",
            "Step [198/882]\t Loss: 0.1778196096420288\t Accuracy: 0.7477760910987854\n",
            "Step [199/882]\t Loss: 0.3462286591529846\t Accuracy: 0.6754719614982605\n",
            "Step [200/882]\t Loss: 0.47347161173820496\t Accuracy: 0.5837793350219727\n",
            "Step [201/882]\t Loss: 0.6384578943252563\t Accuracy: 0.5217117071151733\n",
            "Step [202/882]\t Loss: 0.2728526294231415\t Accuracy: 0.7174451351165771\n",
            "Step [203/882]\t Loss: 0.23073503375053406\t Accuracy: 0.7093232870101929\n",
            "Step [204/882]\t Loss: 0.20714698731899261\t Accuracy: 0.7166240811347961\n",
            "Step [205/882]\t Loss: 0.2812986969947815\t Accuracy: 0.669981837272644\n",
            "Step [206/882]\t Loss: 0.20740610361099243\t Accuracy: 0.7001851201057434\n",
            "Step [207/882]\t Loss: 0.4069348871707916\t Accuracy: 0.5303706526756287\n",
            "Step [208/882]\t Loss: 0.6342056393623352\t Accuracy: 0.38553303480148315\n",
            "Step [209/882]\t Loss: 0.28417330980300903\t Accuracy: 0.6385456919670105\n",
            "Step [210/882]\t Loss: 0.3030751347541809\t Accuracy: 0.6001495122909546\n",
            "Step [211/882]\t Loss: 0.3850657641887665\t Accuracy: 0.5174036026000977\n",
            "Step [212/882]\t Loss: 0.3867804706096649\t Accuracy: 0.48800697922706604\n",
            "Step [213/882]\t Loss: 0.34843140840530396\t Accuracy: 0.5048394799232483\n",
            "Step [214/882]\t Loss: 0.2406785786151886\t Accuracy: 0.6104591488838196\n",
            "Step [215/882]\t Loss: 0.19870053231716156\t Accuracy: 0.624665379524231\n",
            "Step [216/882]\t Loss: 0.4783472418785095\t Accuracy: 0.4646525979042053\n",
            "Step [217/882]\t Loss: 0.23264078795909882\t Accuracy: 0.6300237774848938\n",
            "Step [218/882]\t Loss: 0.36187300086021423\t Accuracy: 0.5123047232627869\n",
            "Step [219/882]\t Loss: 0.516649603843689\t Accuracy: 0.5482791066169739\n",
            "Step [220/882]\t Loss: 0.16660816967487335\t Accuracy: 0.6802538633346558\n",
            "Step [221/882]\t Loss: 0.4169141948223114\t Accuracy: 0.5865771770477295\n",
            "Step [222/882]\t Loss: 0.5599077939987183\t Accuracy: 0.4666084349155426\n",
            "Step [223/882]\t Loss: 0.30489736795425415\t Accuracy: 0.5658206343650818\n",
            "Step [224/882]\t Loss: 0.4534088671207428\t Accuracy: 0.5637097358703613\n",
            "Step [225/882]\t Loss: 0.42182499170303345\t Accuracy: 0.5086994767189026\n",
            "Step [226/882]\t Loss: 0.18636122345924377\t Accuracy: 0.6634647846221924\n",
            "Step [227/882]\t Loss: 0.3379138708114624\t Accuracy: 0.534299373626709\n",
            "Step [228/882]\t Loss: 0.5234796404838562\t Accuracy: 0.5336338877677917\n",
            "Step [229/882]\t Loss: 0.36620157957077026\t Accuracy: 0.5777772068977356\n",
            "Step [230/882]\t Loss: 0.45064765214920044\t Accuracy: 0.5331810116767883\n",
            "Step [231/882]\t Loss: 0.3843338191509247\t Accuracy: 0.5549691319465637\n",
            "Step [232/882]\t Loss: 0.3302222490310669\t Accuracy: 0.5830893516540527\n",
            "Step [233/882]\t Loss: 0.4571528136730194\t Accuracy: 0.5381743311882019\n",
            "Step [234/882]\t Loss: 0.36485886573791504\t Accuracy: 0.493339866399765\n",
            "Step [235/882]\t Loss: 0.5578489303588867\t Accuracy: 0.4299001693725586\n",
            "Step [236/882]\t Loss: 0.39405956864356995\t Accuracy: 0.5462470650672913\n",
            "Step [237/882]\t Loss: 0.33883562684059143\t Accuracy: 0.5686177611351013\n",
            "Step [238/882]\t Loss: 0.4674069285392761\t Accuracy: 0.43668419122695923\n",
            "Step [239/882]\t Loss: 0.2968854308128357\t Accuracy: 0.5747817158699036\n",
            "Step [240/882]\t Loss: 0.5115275382995605\t Accuracy: 0.3950987160205841\n",
            "Step [241/882]\t Loss: 0.22074423730373383\t Accuracy: 0.6143232583999634\n",
            "Step [242/882]\t Loss: 0.2701602578163147\t Accuracy: 0.6056163311004639\n",
            "Step [243/882]\t Loss: 0.2534726560115814\t Accuracy: 0.6277664303779602\n",
            "Step [244/882]\t Loss: 0.32385286688804626\t Accuracy: 0.6110520958900452\n",
            "Step [245/882]\t Loss: 0.4082167446613312\t Accuracy: 0.5234466791152954\n",
            "Step [246/882]\t Loss: 0.525280773639679\t Accuracy: 0.4988018870353699\n",
            "Step [247/882]\t Loss: 0.3154534697532654\t Accuracy: 0.6499385237693787\n",
            "Step [248/882]\t Loss: 0.36808714270591736\t Accuracy: 0.6252904534339905\n",
            "Step [249/882]\t Loss: 0.19431321322917938\t Accuracy: 0.6947848796844482\n",
            "Step [250/882]\t Loss: 0.23510101437568665\t Accuracy: 0.6699705719947815\n",
            "Step [251/882]\t Loss: 0.49489662051200867\t Accuracy: 0.5093753933906555\n",
            "Step [252/882]\t Loss: 0.4127737581729889\t Accuracy: 0.5963402390480042\n",
            "Step [253/882]\t Loss: 0.22396419942378998\t Accuracy: 0.6787485480308533\n",
            "Step [254/882]\t Loss: 0.30170029401779175\t Accuracy: 0.6284571886062622\n",
            "Step [255/882]\t Loss: 0.3509458303451538\t Accuracy: 0.6198042035102844\n",
            "Step [256/882]\t Loss: 0.561109721660614\t Accuracy: 0.5579392313957214\n",
            "Step [257/882]\t Loss: 0.21444959938526154\t Accuracy: 0.6656036972999573\n",
            "Step [258/882]\t Loss: 0.560479462146759\t Accuracy: 0.3716978430747986\n",
            "Step [259/882]\t Loss: 0.21331439912319183\t Accuracy: 0.6534944176673889\n",
            "Step [260/882]\t Loss: 0.32316190004348755\t Accuracy: 0.6127099394798279\n",
            "Step [261/882]\t Loss: 0.31921321153640747\t Accuracy: 0.5969759225845337\n",
            "Step [262/882]\t Loss: 0.4744126796722412\t Accuracy: 0.4936160147190094\n",
            "Step [263/882]\t Loss: 0.4006011486053467\t Accuracy: 0.5063424110412598\n",
            "Step [264/882]\t Loss: 0.5375616550445557\t Accuracy: 0.37344294786453247\n",
            "Step [265/882]\t Loss: 0.5591059923171997\t Accuracy: 0.37435948848724365\n",
            "Step [266/882]\t Loss: 0.4942159056663513\t Accuracy: 0.4433489143848419\n",
            "Step [267/882]\t Loss: 0.36928993463516235\t Accuracy: 0.5335037708282471\n",
            "Step [268/882]\t Loss: 0.4419810473918915\t Accuracy: 0.4537828862667084\n",
            "Step [269/882]\t Loss: 0.4987867474555969\t Accuracy: 0.42116478085517883\n",
            "Step [270/882]\t Loss: 0.46745678782463074\t Accuracy: 0.48736461997032166\n",
            "Step [271/882]\t Loss: 0.3022412061691284\t Accuracy: 0.54195237159729\n",
            "Step [272/882]\t Loss: 0.3569739758968353\t Accuracy: 0.5247500538825989\n",
            "Step [273/882]\t Loss: 0.2767643630504608\t Accuracy: 0.5669646263122559\n",
            "Step [274/882]\t Loss: 0.3813614845275879\t Accuracy: 0.4814968705177307\n",
            "Step [275/882]\t Loss: 0.31974899768829346\t Accuracy: 0.587634265422821\n",
            "Step [276/882]\t Loss: 0.32516664266586304\t Accuracy: 0.6081538796424866\n",
            "Step [277/882]\t Loss: 0.4664261043071747\t Accuracy: 0.5006093978881836\n",
            "Step [278/882]\t Loss: 0.3406071066856384\t Accuracy: 0.6083237528800964\n",
            "Step [279/882]\t Loss: 0.44772693514823914\t Accuracy: 0.5278735160827637\n",
            "Step [280/882]\t Loss: 0.4264940321445465\t Accuracy: 0.5949254631996155\n",
            "Step [281/882]\t Loss: 0.7368047833442688\t Accuracy: 0.5092700123786926\n",
            "Step [282/882]\t Loss: 0.3547155261039734\t Accuracy: 0.6071203351020813\n",
            "Step [283/882]\t Loss: 0.3056904077529907\t Accuracy: 0.612830400466919\n",
            "Step [284/882]\t Loss: 0.22066356241703033\t Accuracy: 0.637732744216919\n",
            "Step [285/882]\t Loss: 0.5046598315238953\t Accuracy: 0.46671491861343384\n",
            "Step [286/882]\t Loss: 0.29445335268974304\t Accuracy: 0.6028491854667664\n",
            "Step [287/882]\t Loss: 0.4044150710105896\t Accuracy: 0.48413556814193726\n",
            "Step [288/882]\t Loss: 0.4057087302207947\t Accuracy: 0.4898899793624878\n",
            "Step [289/882]\t Loss: 0.3726010024547577\t Accuracy: 0.4907551407814026\n",
            "Step [290/882]\t Loss: 0.42980140447616577\t Accuracy: 0.4727502465248108\n",
            "Step [291/882]\t Loss: 0.4337003827095032\t Accuracy: 0.54835045337677\n",
            "Step [292/882]\t Loss: 0.555922269821167\t Accuracy: 0.5091803073883057\n",
            "Step [293/882]\t Loss: 0.34161338210105896\t Accuracy: 0.5693873167037964\n",
            "Step [294/882]\t Loss: 0.572618305683136\t Accuracy: 0.5021511912345886\n",
            "Step [295/882]\t Loss: 0.4893873929977417\t Accuracy: 0.4509917199611664\n",
            "Step [296/882]\t Loss: 0.44644731283187866\t Accuracy: 0.44335928559303284\n",
            "Step [297/882]\t Loss: 0.4798327088356018\t Accuracy: 0.45881369709968567\n",
            "Step [298/882]\t Loss: 0.3531312346458435\t Accuracy: 0.5265133380889893\n",
            "Step [299/882]\t Loss: 0.29900532960891724\t Accuracy: 0.5533290505409241\n",
            "Step [300/882]\t Loss: 0.38687679171562195\t Accuracy: 0.5315681099891663\n",
            "Step [301/882]\t Loss: 0.4566856324672699\t Accuracy: 0.46403199434280396\n",
            "Step [302/882]\t Loss: 0.35984301567077637\t Accuracy: 0.5650331974029541\n",
            "Step [303/882]\t Loss: 0.39613184332847595\t Accuracy: 0.4795483946800232\n",
            "Step [304/882]\t Loss: 0.4007083475589752\t Accuracy: 0.5792184472084045\n",
            "Step [305/882]\t Loss: 0.29245924949645996\t Accuracy: 0.6301742792129517\n",
            "Step [306/882]\t Loss: 0.43029987812042236\t Accuracy: 0.5849088430404663\n",
            "Step [307/882]\t Loss: 0.529175341129303\t Accuracy: 0.479429692029953\n",
            "Step [308/882]\t Loss: 0.510832667350769\t Accuracy: 0.4858793020248413\n",
            "Step [309/882]\t Loss: 0.36243936419487\t Accuracy: 0.5986771583557129\n",
            "Step [310/882]\t Loss: 0.26955005526542664\t Accuracy: 0.6333329081535339\n",
            "Step [311/882]\t Loss: 0.39933109283447266\t Accuracy: 0.512849748134613\n",
            "Step [312/882]\t Loss: 0.451370507478714\t Accuracy: 0.5795361399650574\n",
            "Step [313/882]\t Loss: 0.23227690160274506\t Accuracy: 0.6397908329963684\n",
            "Step [314/882]\t Loss: 0.47512009739875793\t Accuracy: 0.49659332633018494\n",
            "Step [315/882]\t Loss: 0.4790688753128052\t Accuracy: 0.4917655289173126\n",
            "Step [316/882]\t Loss: 0.3745880424976349\t Accuracy: 0.4898081421852112\n",
            "Step [317/882]\t Loss: 0.27891191840171814\t Accuracy: 0.6082558631896973\n",
            "Step [318/882]\t Loss: 0.41097304224967957\t Accuracy: 0.515001118183136\n",
            "Step [319/882]\t Loss: 0.4416022300720215\t Accuracy: 0.5493537187576294\n",
            "Step [320/882]\t Loss: 0.38182929158210754\t Accuracy: 0.5751004815101624\n",
            "Step [321/882]\t Loss: 0.26927444338798523\t Accuracy: 0.6101142168045044\n",
            "Step [322/882]\t Loss: 0.20725175738334656\t Accuracy: 0.6476243734359741\n",
            "Step [323/882]\t Loss: 0.2211150825023651\t Accuracy: 0.6442481875419617\n",
            "Step [324/882]\t Loss: 0.43215638399124146\t Accuracy: 0.5668326020240784\n",
            "Step [325/882]\t Loss: 0.19569168984889984\t Accuracy: 0.6806197762489319\n",
            "Step [326/882]\t Loss: 0.5184193849563599\t Accuracy: 0.49071475863456726\n",
            "Step [327/882]\t Loss: 0.36602121591567993\t Accuracy: 0.5469372272491455\n",
            "Step [328/882]\t Loss: 0.2570127546787262\t Accuracy: 0.6543759703636169\n",
            "Step [329/882]\t Loss: 0.3016287088394165\t Accuracy: 0.659459114074707\n",
            "Step [330/882]\t Loss: 0.659770667552948\t Accuracy: 0.4667607545852661\n",
            "Step [331/882]\t Loss: 0.4969181418418884\t Accuracy: 0.5101776719093323\n",
            "Step [332/882]\t Loss: 0.3341786563396454\t Accuracy: 0.6278533339500427\n",
            "Step [333/882]\t Loss: 0.26928627490997314\t Accuracy: 0.6326422095298767\n",
            "Step [334/882]\t Loss: 0.6653483510017395\t Accuracy: 0.3615034520626068\n",
            "Step [335/882]\t Loss: 0.3947969973087311\t Accuracy: 0.5039010047912598\n",
            "Step [336/882]\t Loss: 0.5021079778671265\t Accuracy: 0.4431353509426117\n",
            "Step [337/882]\t Loss: 0.4472499489784241\t Accuracy: 0.5361927151679993\n",
            "Step [338/882]\t Loss: 0.4385225474834442\t Accuracy: 0.5071190595626831\n",
            "Step [339/882]\t Loss: 0.3032313287258148\t Accuracy: 0.5524415969848633\n",
            "Step [340/882]\t Loss: 0.31598642468452454\t Accuracy: 0.544825553894043\n",
            "Step [341/882]\t Loss: 0.2977674603462219\t Accuracy: 0.5628446936607361\n",
            "Step [342/882]\t Loss: 0.38227057456970215\t Accuracy: 0.5398139357566833\n",
            "Step [343/882]\t Loss: 0.4026205241680145\t Accuracy: 0.47543200850486755\n",
            "Step [344/882]\t Loss: 0.2746812403202057\t Accuracy: 0.5957361459732056\n",
            "Step [345/882]\t Loss: 0.5052423477172852\t Accuracy: 0.45116743445396423\n",
            "Step [346/882]\t Loss: 0.4844132661819458\t Accuracy: 0.4761681854724884\n",
            "Step [347/882]\t Loss: 0.39552968740463257\t Accuracy: 0.5260601043701172\n",
            "Step [348/882]\t Loss: 0.3042888939380646\t Accuracy: 0.6189466714859009\n",
            "Step [349/882]\t Loss: 0.3841874301433563\t Accuracy: 0.5152420401573181\n",
            "Step [350/882]\t Loss: 0.29728490114212036\t Accuracy: 0.6226480603218079\n",
            "Step [351/882]\t Loss: 0.2236137092113495\t Accuracy: 0.6513562798500061\n",
            "Step [352/882]\t Loss: 0.5539405941963196\t Accuracy: 0.4748217761516571\n",
            "Step [353/882]\t Loss: 0.17646977305412292\t Accuracy: 0.6928935647010803\n",
            "Step [354/882]\t Loss: 0.33717015385627747\t Accuracy: 0.6214365363121033\n",
            "Step [355/882]\t Loss: 0.3516519367694855\t Accuracy: 0.6250481605529785\n",
            "Step [356/882]\t Loss: 0.7339722514152527\t Accuracy: 0.5115944147109985\n",
            "Step [357/882]\t Loss: 0.350043386220932\t Accuracy: 0.6073980331420898\n",
            "Step [358/882]\t Loss: 0.3468966782093048\t Accuracy: 0.609926164150238\n",
            "Step [359/882]\t Loss: 0.3909243643283844\t Accuracy: 0.5165868401527405\n",
            "Step [360/882]\t Loss: 0.386819064617157\t Accuracy: 0.49898162484169006\n",
            "Step [361/882]\t Loss: 0.1977558583021164\t Accuracy: 0.6444604396820068\n",
            "Step [362/882]\t Loss: 0.5313085913658142\t Accuracy: 0.46939772367477417\n",
            "Step [363/882]\t Loss: 0.3581337630748749\t Accuracy: 0.574737012386322\n",
            "Step [364/882]\t Loss: 0.2649637758731842\t Accuracy: 0.6083370447158813\n",
            "Step [365/882]\t Loss: 0.21485990285873413\t Accuracy: 0.6294018030166626\n",
            "Step [366/882]\t Loss: 0.3574347198009491\t Accuracy: 0.5866785049438477\n",
            "Step [367/882]\t Loss: 0.22708521783351898\t Accuracy: 0.6455246806144714\n",
            "Step [368/882]\t Loss: 0.2758212685585022\t Accuracy: 0.6244721412658691\n",
            "Step [369/882]\t Loss: 0.3548823297023773\t Accuracy: 0.6173862814903259\n",
            "Step [370/882]\t Loss: 0.4276532232761383\t Accuracy: 0.5177298784255981\n",
            "Step [371/882]\t Loss: 0.2381601780653\t Accuracy: 0.6796285510063171\n",
            "Step [372/882]\t Loss: 0.4101249873638153\t Accuracy: 0.6058258414268494\n",
            "Step [373/882]\t Loss: 0.17516294121742249\t Accuracy: 0.7312118411064148\n",
            "Step [374/882]\t Loss: 0.39825108647346497\t Accuracy: 0.6123105883598328\n",
            "Step [375/882]\t Loss: 0.4642955958843231\t Accuracy: 0.5718269944190979\n",
            "Step [376/882]\t Loss: 0.39099690318107605\t Accuracy: 0.6198735237121582\n",
            "Step [377/882]\t Loss: 0.39608266949653625\t Accuracy: 0.5577449202537537\n",
            "Step [378/882]\t Loss: 0.4375571310520172\t Accuracy: 0.5956624150276184\n",
            "Step [379/882]\t Loss: 0.36447858810424805\t Accuracy: 0.6117439270019531\n",
            "Step [380/882]\t Loss: 0.3312373757362366\t Accuracy: 0.6201562285423279\n",
            "Step [381/882]\t Loss: 0.7039368152618408\t Accuracy: 0.35490092635154724\n",
            "Step [382/882]\t Loss: 0.43071219325065613\t Accuracy: 0.5683537721633911\n",
            "Step [383/882]\t Loss: 0.4117824137210846\t Accuracy: 0.5587583184242249\n",
            "Step [384/882]\t Loss: 0.5262885689735413\t Accuracy: 0.44348376989364624\n",
            "Step [385/882]\t Loss: 0.43846893310546875\t Accuracy: 0.5218693614006042\n",
            "Step [386/882]\t Loss: 0.4209662079811096\t Accuracy: 0.5098688006401062\n",
            "Step [387/882]\t Loss: 0.48519065976142883\t Accuracy: 0.45140570402145386\n",
            "Step [388/882]\t Loss: 0.5121363997459412\t Accuracy: 0.42154461145401\n",
            "Step [389/882]\t Loss: 0.3147433400154114\t Accuracy: 0.5215199589729309\n",
            "Step [390/882]\t Loss: 0.3623522222042084\t Accuracy: 0.5201817154884338\n",
            "Step [391/882]\t Loss: 0.36348462104797363\t Accuracy: 0.5315462350845337\n",
            "Step [392/882]\t Loss: 0.43197548389434814\t Accuracy: 0.5326604247093201\n",
            "Step [393/882]\t Loss: 0.6397488117218018\t Accuracy: 0.3659251630306244\n",
            "Step [394/882]\t Loss: 0.3406088650226593\t Accuracy: 0.5856696963310242\n",
            "Step [395/882]\t Loss: 0.28168293833732605\t Accuracy: 0.6111053228378296\n",
            "Step [396/882]\t Loss: 0.31287142634391785\t Accuracy: 0.6005386710166931\n",
            "Step [397/882]\t Loss: 0.49127069115638733\t Accuracy: 0.4939737617969513\n",
            "Step [398/882]\t Loss: 0.4549286961555481\t Accuracy: 0.5029446482658386\n",
            "Step [399/882]\t Loss: 0.2762649357318878\t Accuracy: 0.6380967497825623\n",
            "Step [400/882]\t Loss: 0.2840201258659363\t Accuracy: 0.6261482238769531\n",
            "Step [401/882]\t Loss: 0.2522979974746704\t Accuracy: 0.6475646495819092\n",
            "Step [402/882]\t Loss: 0.499656081199646\t Accuracy: 0.5056317448616028\n",
            "Step [403/882]\t Loss: 0.38597872853279114\t Accuracy: 0.6073232293128967\n",
            "Step [404/882]\t Loss: 0.545444130897522\t Accuracy: 0.5478731393814087\n",
            "Step [405/882]\t Loss: 0.5177545547485352\t Accuracy: 0.5022373795509338\n",
            "Step [406/882]\t Loss: 0.3139920234680176\t Accuracy: 0.6164302229881287\n",
            "Step [407/882]\t Loss: 0.34517326951026917\t Accuracy: 0.5875858068466187\n",
            "Step [408/882]\t Loss: 0.22964249551296234\t Accuracy: 0.6388360857963562\n",
            "Step [409/882]\t Loss: 0.3812327980995178\t Accuracy: 0.5748752355575562\n",
            "Step [410/882]\t Loss: 0.41928383708000183\t Accuracy: 0.49162495136260986\n",
            "Step [411/882]\t Loss: 0.41585347056388855\t Accuracy: 0.563019335269928\n",
            "Step [412/882]\t Loss: 0.45363059639930725\t Accuracy: 0.4839385747909546\n",
            "Step [413/882]\t Loss: 0.4845222532749176\t Accuracy: 0.46497032046318054\n",
            "Step [414/882]\t Loss: 0.5134658217430115\t Accuracy: 0.3730573058128357\n",
            "Step [415/882]\t Loss: 0.2329450100660324\t Accuracy: 0.6187379956245422\n",
            "Step [416/882]\t Loss: 0.2545662522315979\t Accuracy: 0.6076099276542664\n",
            "Step [417/882]\t Loss: 0.37509387731552124\t Accuracy: 0.5107109546661377\n",
            "Step [418/882]\t Loss: 0.24189873039722443\t Accuracy: 0.623491644859314\n",
            "Step [419/882]\t Loss: 0.5069054365158081\t Accuracy: 0.48460665345191956\n",
            "Step [420/882]\t Loss: 0.3259725868701935\t Accuracy: 0.612614095211029\n",
            "Step [421/882]\t Loss: 0.2967604398727417\t Accuracy: 0.6267085075378418\n",
            "Step [422/882]\t Loss: 0.4911852777004242\t Accuracy: 0.4883548319339752\n",
            "Step [423/882]\t Loss: 0.21783658862113953\t Accuracy: 0.6642597913742065\n",
            "Step [424/882]\t Loss: 0.17261572182178497\t Accuracy: 0.6880308985710144\n",
            "Step [425/882]\t Loss: 0.5755496621131897\t Accuracy: 0.4133603870868683\n",
            "Step [426/882]\t Loss: 0.2717585861682892\t Accuracy: 0.643132209777832\n",
            "Step [427/882]\t Loss: 0.3858059346675873\t Accuracy: 0.6074557900428772\n",
            "Step [428/882]\t Loss: 0.31996840238571167\t Accuracy: 0.6251636147499084\n",
            "Step [429/882]\t Loss: 0.41137897968292236\t Accuracy: 0.5267316102981567\n",
            "Step [430/882]\t Loss: 0.18967503309249878\t Accuracy: 0.687288761138916\n",
            "Step [431/882]\t Loss: 0.2688557207584381\t Accuracy: 0.6363855600357056\n",
            "Step [432/882]\t Loss: 0.3627394437789917\t Accuracy: 0.6200700998306274\n",
            "Step [433/882]\t Loss: 0.524864673614502\t Accuracy: 0.4880189001560211\n",
            "Step [434/882]\t Loss: 0.32831165194511414\t Accuracy: 0.6227557063102722\n",
            "Step [435/882]\t Loss: 0.15903985500335693\t Accuracy: 0.6945255994796753\n",
            "Step [436/882]\t Loss: 0.4236350357532501\t Accuracy: 0.5160424113273621\n",
            "Step [437/882]\t Loss: 0.4663790762424469\t Accuracy: 0.5565350651741028\n",
            "Step [438/882]\t Loss: 0.6213269233703613\t Accuracy: 0.3659478724002838\n",
            "Step [439/882]\t Loss: 0.4743126928806305\t Accuracy: 0.4853421151638031\n",
            "Step [440/882]\t Loss: 0.44105926156044006\t Accuracy: 0.481090247631073\n",
            "Step [441/882]\t Loss: 0.2477012574672699\t Accuracy: 0.611761212348938\n",
            "Step [442/882]\t Loss: 0.29848408699035645\t Accuracy: 0.5789481401443481\n",
            "Step [443/882]\t Loss: 0.4764125943183899\t Accuracy: 0.4804830253124237\n",
            "Step [444/882]\t Loss: 0.5502181649208069\t Accuracy: 0.4308162331581116\n",
            "Step [445/882]\t Loss: 0.3104666769504547\t Accuracy: 0.5670278668403625\n",
            "Step [446/882]\t Loss: 0.36208775639533997\t Accuracy: 0.5025485157966614\n",
            "Step [447/882]\t Loss: 0.22876806557178497\t Accuracy: 0.5927870869636536\n",
            "Step [448/882]\t Loss: 0.3919348418712616\t Accuracy: 0.4767827093601227\n",
            "Step [449/882]\t Loss: 0.5623672604560852\t Accuracy: 0.4345034658908844\n",
            "Step [450/882]\t Loss: 0.33166760206222534\t Accuracy: 0.55658358335495\n",
            "Step [451/882]\t Loss: 0.42828431725502014\t Accuracy: 0.4759669303894043\n",
            "Step [452/882]\t Loss: 0.29566147923469543\t Accuracy: 0.5925192832946777\n",
            "Step [453/882]\t Loss: 0.3668093681335449\t Accuracy: 0.5009551644325256\n",
            "Step [454/882]\t Loss: 0.4921036958694458\t Accuracy: 0.5393221974372864\n",
            "Step [455/882]\t Loss: 0.4625895023345947\t Accuracy: 0.5456061363220215\n",
            "Step [456/882]\t Loss: 0.36391013860702515\t Accuracy: 0.5746650099754333\n",
            "Step [457/882]\t Loss: 0.39127224683761597\t Accuracy: 0.5242741703987122\n",
            "Step [458/882]\t Loss: 0.4010062515735626\t Accuracy: 0.4941975772380829\n",
            "Step [459/882]\t Loss: 0.4064878821372986\t Accuracy: 0.5639488101005554\n",
            "Step [460/882]\t Loss: 0.5174666047096252\t Accuracy: 0.3899392783641815\n",
            "Step [461/882]\t Loss: 0.4056800305843353\t Accuracy: 0.4951186776161194\n",
            "Step [462/882]\t Loss: 0.41392698884010315\t Accuracy: 0.5452732443809509\n",
            "Step [463/882]\t Loss: 0.21121083199977875\t Accuracy: 0.6336519718170166\n",
            "Step [464/882]\t Loss: 0.40138718485832214\t Accuracy: 0.5509614944458008\n",
            "Step [465/882]\t Loss: 0.6149808764457703\t Accuracy: 0.3564334213733673\n",
            "Step [466/882]\t Loss: 0.4780083894729614\t Accuracy: 0.5254766941070557\n",
            "Step [467/882]\t Loss: 0.30614814162254333\t Accuracy: 0.5813961029052734\n",
            "Step [468/882]\t Loss: 0.4022999405860901\t Accuracy: 0.4841262996196747\n",
            "Step [469/882]\t Loss: 0.3274417221546173\t Accuracy: 0.5596997737884521\n",
            "Step [470/882]\t Loss: 0.25788527727127075\t Accuracy: 0.5939383506774902\n",
            "Step [471/882]\t Loss: 0.49122971296310425\t Accuracy: 0.46437105536460876\n",
            "Step [472/882]\t Loss: 0.2230842411518097\t Accuracy: 0.6147539019584656\n",
            "Step [473/882]\t Loss: 0.4057803750038147\t Accuracy: 0.4934425354003906\n",
            "Step [474/882]\t Loss: 0.4486072063446045\t Accuracy: 0.48024824261665344\n",
            "Step [475/882]\t Loss: 0.5809113383293152\t Accuracy: 0.45123210549354553\n",
            "Step [476/882]\t Loss: 0.281843364238739\t Accuracy: 0.6081731915473938\n",
            "Step [477/882]\t Loss: 0.30011123418807983\t Accuracy: 0.6123082637786865\n",
            "Step [478/882]\t Loss: 0.239625483751297\t Accuracy: 0.634516179561615\n",
            "Step [479/882]\t Loss: 0.4347778260707855\t Accuracy: 0.5646817684173584\n",
            "Step [480/882]\t Loss: 0.36693647503852844\t Accuracy: 0.5176933407783508\n",
            "Step [481/882]\t Loss: 0.368291437625885\t Accuracy: 0.5735621452331543\n",
            "Step [482/882]\t Loss: 0.38797539472579956\t Accuracy: 0.5762450695037842\n",
            "Step [483/882]\t Loss: 0.3145441710948944\t Accuracy: 0.6222912669181824\n",
            "Step [484/882]\t Loss: 0.3279930055141449\t Accuracy: 0.6065518260002136\n",
            "Step [485/882]\t Loss: 0.25483381748199463\t Accuracy: 0.6404265761375427\n",
            "Step [486/882]\t Loss: 0.3288968801498413\t Accuracy: 0.6174858808517456\n",
            "Step [487/882]\t Loss: 0.3245910704135895\t Accuracy: 0.6294371485710144\n",
            "Step [488/882]\t Loss: 0.49739548563957214\t Accuracy: 0.5644534826278687\n",
            "Step [489/882]\t Loss: 0.3341310918331146\t Accuracy: 0.6102909445762634\n",
            "Step [490/882]\t Loss: 0.47818949818611145\t Accuracy: 0.5087629556655884\n",
            "Step [491/882]\t Loss: 0.5067403316497803\t Accuracy: 0.545333206653595\n",
            "Step [492/882]\t Loss: 0.5970767736434937\t Accuracy: 0.36856919527053833\n",
            "Step [493/882]\t Loss: 0.4430176615715027\t Accuracy: 0.5084558129310608\n",
            "Step [494/882]\t Loss: 0.4094018042087555\t Accuracy: 0.5551643371582031\n",
            "Step [495/882]\t Loss: 0.4270177483558655\t Accuracy: 0.4717634320259094\n",
            "Step [496/882]\t Loss: 0.37624460458755493\t Accuracy: 0.5548844337463379\n",
            "Step [497/882]\t Loss: 0.4525684416294098\t Accuracy: 0.4787214398384094\n",
            "Step [498/882]\t Loss: 0.4533429443836212\t Accuracy: 0.4606638252735138\n",
            "Step [499/882]\t Loss: 0.3493557870388031\t Accuracy: 0.5362690091133118\n",
            "Step [500/882]\t Loss: 0.38987040519714355\t Accuracy: 0.5242457389831543\n",
            "Step [501/882]\t Loss: 0.410414457321167\t Accuracy: 0.5253403782844543\n",
            "Step [502/882]\t Loss: 0.27108246088027954\t Accuracy: 0.5836233496665955\n",
            "Step [503/882]\t Loss: 0.6609636545181274\t Accuracy: 0.3315822184085846\n",
            "Step [504/882]\t Loss: 0.45270150899887085\t Accuracy: 0.45887622237205505\n",
            "Step [505/882]\t Loss: 0.4088599979877472\t Accuracy: 0.49620798230171204\n",
            "Step [506/882]\t Loss: 0.47148197889328003\t Accuracy: 0.46214309334754944\n",
            "Step [507/882]\t Loss: 0.3249088227748871\t Accuracy: 0.5739359855651855\n",
            "Step [508/882]\t Loss: 0.5738227367401123\t Accuracy: 0.4634338915348053\n",
            "Step [509/882]\t Loss: 0.3100866973400116\t Accuracy: 0.5848459005355835\n",
            "Step [510/882]\t Loss: 0.48179882764816284\t Accuracy: 0.5272279381752014\n",
            "Step [511/882]\t Loss: 0.4884360134601593\t Accuracy: 0.4593532979488373\n",
            "Step [512/882]\t Loss: 0.2766825258731842\t Accuracy: 0.5921803712844849\n",
            "Step [513/882]\t Loss: 0.38766878843307495\t Accuracy: 0.5620591044425964\n",
            "Step [514/882]\t Loss: 0.22323919832706451\t Accuracy: 0.6165529489517212\n",
            "Step [515/882]\t Loss: 0.22259299457073212\t Accuracy: 0.6375442147254944\n",
            "Step [516/882]\t Loss: 0.20017535984516144\t Accuracy: 0.6533820033073425\n",
            "Step [517/882]\t Loss: 0.3407527804374695\t Accuracy: 0.5280012488365173\n",
            "Step [518/882]\t Loss: 0.684632420539856\t Accuracy: 0.3683057725429535\n",
            "Step [519/882]\t Loss: 0.4538937509059906\t Accuracy: 0.5248997211456299\n",
            "Step [520/882]\t Loss: 0.6100257039070129\t Accuracy: 0.5395301580429077\n",
            "Step [521/882]\t Loss: 0.6361140608787537\t Accuracy: 0.4749692380428314\n",
            "Step [522/882]\t Loss: 0.3336801826953888\t Accuracy: 0.6005507707595825\n",
            "Step [523/882]\t Loss: 0.35399946570396423\t Accuracy: 0.5789847373962402\n",
            "Step [524/882]\t Loss: 0.3460589647293091\t Accuracy: 0.5855076313018799\n",
            "Step [525/882]\t Loss: 0.4235711693763733\t Accuracy: 0.4815077483654022\n",
            "Step [526/882]\t Loss: 0.358193039894104\t Accuracy: 0.49575191736221313\n",
            "Step [527/882]\t Loss: 0.3322012722492218\t Accuracy: 0.5648912191390991\n",
            "Step [528/882]\t Loss: 0.6076890230178833\t Accuracy: 0.38080981373786926\n",
            "Step [529/882]\t Loss: 0.45891135931015015\t Accuracy: 0.458890438079834\n",
            "Step [530/882]\t Loss: 0.36487460136413574\t Accuracy: 0.5534531474113464\n",
            "Step [531/882]\t Loss: 0.49824509024620056\t Accuracy: 0.44024232029914856\n",
            "Step [532/882]\t Loss: 0.3884528577327728\t Accuracy: 0.4687770903110504\n",
            "Step [533/882]\t Loss: 0.4200461208820343\t Accuracy: 0.46480411291122437\n",
            "Step [534/882]\t Loss: 0.44701218605041504\t Accuracy: 0.5203161239624023\n",
            "Step [535/882]\t Loss: 0.3395502269268036\t Accuracy: 0.499188095331192\n",
            "Step [536/882]\t Loss: 0.534244179725647\t Accuracy: 0.3733428716659546\n",
            "Step [537/882]\t Loss: 0.5726983547210693\t Accuracy: 0.42833399772644043\n",
            "Step [538/882]\t Loss: 0.3964228332042694\t Accuracy: 0.5330906510353088\n",
            "Step [539/882]\t Loss: 0.3291516900062561\t Accuracy: 0.5523818135261536\n",
            "Step [540/882]\t Loss: 0.6335336565971375\t Accuracy: 0.469956636428833\n",
            "Step [541/882]\t Loss: 0.31615927815437317\t Accuracy: 0.5514474511146545\n",
            "Step [542/882]\t Loss: 0.30205512046813965\t Accuracy: 0.5614907741546631\n",
            "Step [543/882]\t Loss: 0.4967782497406006\t Accuracy: 0.3711996078491211\n",
            "Step [544/882]\t Loss: 0.35817626118659973\t Accuracy: 0.4676930606365204\n",
            "Step [545/882]\t Loss: 0.5129611492156982\t Accuracy: 0.4726578891277313\n",
            "Step [546/882]\t Loss: 0.45431336760520935\t Accuracy: 0.46683573722839355\n",
            "Step [547/882]\t Loss: 0.3203714191913605\t Accuracy: 0.5615532994270325\n",
            "Step [548/882]\t Loss: 0.39651840925216675\t Accuracy: 0.5500303506851196\n",
            "Step [549/882]\t Loss: 0.2473486214876175\t Accuracy: 0.606116533279419\n",
            "Step [550/882]\t Loss: 0.2954670190811157\t Accuracy: 0.5853254795074463\n",
            "Step [551/882]\t Loss: 0.3202084004878998\t Accuracy: 0.5861092209815979\n",
            "Step [552/882]\t Loss: 0.6273766160011292\t Accuracy: 0.5096674561500549\n",
            "Step [553/882]\t Loss: 0.6803133487701416\t Accuracy: 0.46044236421585083\n",
            "Step [554/882]\t Loss: 0.42498740553855896\t Accuracy: 0.5693197846412659\n",
            "Step [555/882]\t Loss: 0.2872646450996399\t Accuracy: 0.5961488485336304\n",
            "Step [556/882]\t Loss: 0.37107986211776733\t Accuracy: 0.4954807758331299\n",
            "Step [557/882]\t Loss: 0.24673818051815033\t Accuracy: 0.60457444190979\n",
            "Step [558/882]\t Loss: 0.33888402581214905\t Accuracy: 0.4964178502559662\n",
            "Step [559/882]\t Loss: 0.38900554180145264\t Accuracy: 0.5529835224151611\n",
            "Step [560/882]\t Loss: 0.31660908460617065\t Accuracy: 0.5873052477836609\n",
            "Step [561/882]\t Loss: 0.5063641667366028\t Accuracy: 0.47842836380004883\n",
            "Step [562/882]\t Loss: 0.23238001763820648\t Accuracy: 0.6380364298820496\n",
            "Step [563/882]\t Loss: 0.27076849341392517\t Accuracy: 0.6308032274246216\n",
            "Step [564/882]\t Loss: 0.3876569867134094\t Accuracy: 0.5892324447631836\n",
            "Step [565/882]\t Loss: 0.4856114089488983\t Accuracy: 0.5139727592468262\n",
            "Step [566/882]\t Loss: 0.3313309848308563\t Accuracy: 0.6176962852478027\n",
            "Step [567/882]\t Loss: 0.29395541548728943\t Accuracy: 0.6281550526618958\n",
            "Step [568/882]\t Loss: 0.26107728481292725\t Accuracy: 0.6488958597183228\n",
            "Step [569/882]\t Loss: 0.2858763635158539\t Accuracy: 0.6392716765403748\n",
            "Step [570/882]\t Loss: 0.4108021855354309\t Accuracy: 0.5351396799087524\n",
            "Step [571/882]\t Loss: 0.23977504670619965\t Accuracy: 0.6674572229385376\n",
            "Step [572/882]\t Loss: 0.23959337174892426\t Accuracy: 0.6742066144943237\n",
            "Step [573/882]\t Loss: 0.25627827644348145\t Accuracy: 0.6721611022949219\n",
            "Step [574/882]\t Loss: 0.28870731592178345\t Accuracy: 0.6691901087760925\n",
            "Step [575/882]\t Loss: 0.3633876442909241\t Accuracy: 0.6368663907051086\n",
            "Step [576/882]\t Loss: 0.20847460627555847\t Accuracy: 0.7020664215087891\n",
            "Step [577/882]\t Loss: 0.4682271480560303\t Accuracy: 0.5955007672309875\n",
            "Step [578/882]\t Loss: 0.20882265269756317\t Accuracy: 0.7051950097084045\n",
            "Step [579/882]\t Loss: 0.28126806020736694\t Accuracy: 0.6704361438751221\n",
            "Step [580/882]\t Loss: 0.19839727878570557\t Accuracy: 0.715793251991272\n",
            "Step [581/882]\t Loss: 0.5579474568367004\t Accuracy: 0.5088930726051331\n",
            "Step [582/882]\t Loss: 0.8585273027420044\t Accuracy: 0.3461477756500244\n",
            "Step [583/882]\t Loss: 0.2692384719848633\t Accuracy: 0.6684622168540955\n",
            "Step [584/882]\t Loss: 0.2470444291830063\t Accuracy: 0.6429604887962341\n",
            "Step [585/882]\t Loss: 0.27609363198280334\t Accuracy: 0.6277721524238586\n",
            "Step [586/882]\t Loss: 0.2303137332201004\t Accuracy: 0.6356566548347473\n",
            "Step [587/882]\t Loss: 0.18141187727451324\t Accuracy: 0.6672452688217163\n",
            "Step [588/882]\t Loss: 0.24756495654582977\t Accuracy: 0.6373083591461182\n",
            "Step [589/882]\t Loss: 0.25075653195381165\t Accuracy: 0.6422361731529236\n",
            "Step [590/882]\t Loss: 0.40522509813308716\t Accuracy: 0.519384503364563\n",
            "Step [591/882]\t Loss: 0.6605294942855835\t Accuracy: 0.45391589403152466\n",
            "Step [592/882]\t Loss: 0.3831317722797394\t Accuracy: 0.5300753712654114\n",
            "Step [593/882]\t Loss: 0.42228221893310547\t Accuracy: 0.5731533169746399\n",
            "Step [594/882]\t Loss: 0.3838694095611572\t Accuracy: 0.5447335839271545\n",
            "Step [595/882]\t Loss: 0.41583251953125\t Accuracy: 0.5395711660385132\n",
            "Step [596/882]\t Loss: 0.26502665877342224\t Accuracy: 0.6210465431213379\n",
            "Step [597/882]\t Loss: 0.5502637028694153\t Accuracy: 0.4539533853530884\n",
            "Step [598/882]\t Loss: 0.2097145915031433\t Accuracy: 0.6460912227630615\n",
            "Step [599/882]\t Loss: 0.4615399241447449\t Accuracy: 0.47764843702316284\n",
            "Step [600/882]\t Loss: 0.4823077917098999\t Accuracy: 0.47654053568840027\n",
            "Step [601/882]\t Loss: 0.2606973350048065\t Accuracy: 0.6150029897689819\n",
            "Step [602/882]\t Loss: 0.36713430285453796\t Accuracy: 0.5066955089569092\n",
            "Step [603/882]\t Loss: 0.5362255573272705\t Accuracy: 0.45485544204711914\n",
            "Step [604/882]\t Loss: 0.641546368598938\t Accuracy: 0.3793923556804657\n",
            "Step [605/882]\t Loss: 0.39253950119018555\t Accuracy: 0.5436693429946899\n",
            "Step [606/882]\t Loss: 0.28997430205345154\t Accuracy: 0.5824922323226929\n",
            "Step [607/882]\t Loss: 0.3635941445827484\t Accuracy: 0.5342653393745422\n",
            "Step [608/882]\t Loss: 0.2815634310245514\t Accuracy: 0.5828139781951904\n",
            "Step [609/882]\t Loss: 0.48930907249450684\t Accuracy: 0.4328053295612335\n",
            "Step [610/882]\t Loss: 0.5348542332649231\t Accuracy: 0.5071307420730591\n",
            "Step [611/882]\t Loss: 0.3839608430862427\t Accuracy: 0.5501278638839722\n",
            "Step [612/882]\t Loss: 0.39889729022979736\t Accuracy: 0.487110435962677\n",
            "Step [613/882]\t Loss: 0.282474160194397\t Accuracy: 0.58694988489151\n",
            "Step [614/882]\t Loss: 0.4663451910018921\t Accuracy: 0.47103583812713623\n",
            "Step [615/882]\t Loss: 0.2450546771287918\t Accuracy: 0.6179102063179016\n",
            "Step [616/882]\t Loss: 0.34036874771118164\t Accuracy: 0.5869992971420288\n",
            "Step [617/882]\t Loss: 0.32976293563842773\t Accuracy: 0.5886223912239075\n",
            "Step [618/882]\t Loss: 0.2381233274936676\t Accuracy: 0.6288478970527649\n",
            "Step [619/882]\t Loss: 0.2088981568813324\t Accuracy: 0.6504449844360352\n",
            "Step [620/882]\t Loss: 0.3703562021255493\t Accuracy: 0.5410414934158325\n",
            "Step [621/882]\t Loss: 0.42685380578041077\t Accuracy: 0.5120116472244263\n",
            "Step [622/882]\t Loss: 0.38020816445350647\t Accuracy: 0.6156671047210693\n",
            "Step [623/882]\t Loss: 0.3592444956302643\t Accuracy: 0.6249191761016846\n",
            "Step [624/882]\t Loss: 0.1604248732328415\t Accuracy: 0.7211824059486389\n",
            "Step [625/882]\t Loss: 0.39224717020988464\t Accuracy: 0.5488137602806091\n",
            "Step [626/882]\t Loss: 0.3553752601146698\t Accuracy: 0.626408040523529\n",
            "Step [627/882]\t Loss: 0.1794392466545105\t Accuracy: 0.7148805856704712\n",
            "Step [628/882]\t Loss: 0.42340946197509766\t Accuracy: 0.6154903769493103\n",
            "Step [629/882]\t Loss: 0.5308675169944763\t Accuracy: 0.5076965689659119\n",
            "Step [630/882]\t Loss: 0.39208027720451355\t Accuracy: 0.6152423024177551\n",
            "Step [631/882]\t Loss: 0.5319406390190125\t Accuracy: 0.4932192265987396\n",
            "Step [632/882]\t Loss: 0.3181023597717285\t Accuracy: 0.6233211159706116\n",
            "Step [633/882]\t Loss: 0.332106351852417\t Accuracy: 0.6054619550704956\n",
            "Step [634/882]\t Loss: 0.5498973727226257\t Accuracy: 0.4635809361934662\n",
            "Step [635/882]\t Loss: 0.37657099962234497\t Accuracy: 0.5678055286407471\n",
            "Step [636/882]\t Loss: 0.5827472805976868\t Accuracy: 0.4203040599822998\n",
            "Step [637/882]\t Loss: 0.3473340570926666\t Accuracy: 0.5656280517578125\n",
            "Step [638/882]\t Loss: 0.5828360319137573\t Accuracy: 0.32552582025527954\n",
            "Step [639/882]\t Loss: 0.5529471039772034\t Accuracy: 0.4018956422805786\n",
            "Step [640/882]\t Loss: 0.5410283207893372\t Accuracy: 0.41912075877189636\n",
            "Step [641/882]\t Loss: 0.46942341327667236\t Accuracy: 0.41654014587402344\n",
            "Step [642/882]\t Loss: 0.48297396302223206\t Accuracy: 0.4192095398902893\n",
            "Step [643/882]\t Loss: 0.4462253451347351\t Accuracy: 0.3996198773384094\n",
            "Step [644/882]\t Loss: 0.34755080938339233\t Accuracy: 0.4981750547885895\n",
            "Step [645/882]\t Loss: 0.37318679690361023\t Accuracy: 0.5178747773170471\n",
            "Step [646/882]\t Loss: 0.5003232955932617\t Accuracy: 0.44776231050491333\n",
            "Step [647/882]\t Loss: 0.5267490148544312\t Accuracy: 0.5059828162193298\n",
            "Step [648/882]\t Loss: 0.38292092084884644\t Accuracy: 0.5481770634651184\n",
            "Step [649/882]\t Loss: 0.2646976113319397\t Accuracy: 0.6055037379264832\n",
            "Step [650/882]\t Loss: 0.40004050731658936\t Accuracy: 0.558819591999054\n",
            "Step [651/882]\t Loss: 0.4334685504436493\t Accuracy: 0.4916699230670929\n",
            "Step [652/882]\t Loss: 0.5061386823654175\t Accuracy: 0.48411160707473755\n",
            "Step [653/882]\t Loss: 0.21191981434822083\t Accuracy: 0.6396434903144836\n",
            "Step [654/882]\t Loss: 0.47622424364089966\t Accuracy: 0.48591431975364685\n",
            "Step [655/882]\t Loss: 0.19946883618831635\t Accuracy: 0.6610460877418518\n",
            "Step [656/882]\t Loss: 0.5239493250846863\t Accuracy: 0.48554885387420654\n",
            "Step [657/882]\t Loss: 0.3605841398239136\t Accuracy: 0.5272648334503174\n",
            "Step [658/882]\t Loss: 0.28862273693084717\t Accuracy: 0.6066974401473999\n",
            "Step [659/882]\t Loss: 0.37946873903274536\t Accuracy: 0.5161599516868591\n",
            "Step [660/882]\t Loss: 0.21052367985248566\t Accuracy: 0.6452833414077759\n",
            "Step [661/882]\t Loss: 0.4695967733860016\t Accuracy: 0.48719990253448486\n",
            "Step [662/882]\t Loss: 0.3930530250072479\t Accuracy: 0.5938854217529297\n",
            "Step [663/882]\t Loss: 0.4033694267272949\t Accuracy: 0.5079860091209412\n",
            "Step [664/882]\t Loss: 0.421325147151947\t Accuracy: 0.4893260598182678\n",
            "Step [665/882]\t Loss: 0.38704031705856323\t Accuracy: 0.5708502531051636\n",
            "Step [666/882]\t Loss: 0.39018240571022034\t Accuracy: 0.4901597201824188\n",
            "Step [667/882]\t Loss: 0.5044835805892944\t Accuracy: 0.44867780804634094\n",
            "Step [668/882]\t Loss: 0.37166348099708557\t Accuracy: 0.47941306233406067\n",
            "Step [669/882]\t Loss: 0.3936396837234497\t Accuracy: 0.45890241861343384\n",
            "Step [670/882]\t Loss: 0.3537009060382843\t Accuracy: 0.47050631046295166\n",
            "Step [671/882]\t Loss: 0.25452205538749695\t Accuracy: 0.5964311957359314\n",
            "Step [672/882]\t Loss: 0.4274965822696686\t Accuracy: 0.48854050040245056\n",
            "Step [673/882]\t Loss: 0.17814984917640686\t Accuracy: 0.6747180819511414\n",
            "Step [674/882]\t Loss: 0.5883112549781799\t Accuracy: 0.47048136591911316\n",
            "Step [675/882]\t Loss: 0.36288508772850037\t Accuracy: 0.6119465231895447\n",
            "Step [676/882]\t Loss: 0.33931517601013184\t Accuracy: 0.6373814940452576\n",
            "Step [677/882]\t Loss: 0.4824349582195282\t Accuracy: 0.5065515041351318\n",
            "Step [678/882]\t Loss: 0.3906744420528412\t Accuracy: 0.5408181548118591\n",
            "Step [679/882]\t Loss: 0.36992743611335754\t Accuracy: 0.6163408160209656\n",
            "Step [680/882]\t Loss: 0.1933133453130722\t Accuracy: 0.6744127869606018\n",
            "Step [681/882]\t Loss: 0.4950193166732788\t Accuracy: 0.5528866052627563\n",
            "Step [682/882]\t Loss: 0.4452885687351227\t Accuracy: 0.5611426830291748\n",
            "Step [683/882]\t Loss: 0.18862544000148773\t Accuracy: 0.6515628099441528\n",
            "Step [684/882]\t Loss: 0.3774891495704651\t Accuracy: 0.5118195414543152\n",
            "Step [685/882]\t Loss: 0.48655760288238525\t Accuracy: 0.47601258754730225\n",
            "Step [686/882]\t Loss: 0.25612619519233704\t Accuracy: 0.6261520385742188\n",
            "Step [687/882]\t Loss: 0.721270740032196\t Accuracy: 0.3658393919467926\n",
            "Step [688/882]\t Loss: 0.4107035994529724\t Accuracy: 0.558745801448822\n",
            "Step [689/882]\t Loss: 0.43827420473098755\t Accuracy: 0.4620790481567383\n",
            "Step [690/882]\t Loss: 0.2664758265018463\t Accuracy: 0.5829228758811951\n",
            "Step [691/882]\t Loss: 0.3020910620689392\t Accuracy: 0.5700268745422363\n",
            "Step [692/882]\t Loss: 0.37006479501724243\t Accuracy: 0.4867488443851471\n",
            "Step [693/882]\t Loss: 0.4404031038284302\t Accuracy: 0.4779702425003052\n",
            "Step [694/882]\t Loss: 0.43537917733192444\t Accuracy: 0.5432345867156982\n",
            "Step [695/882]\t Loss: 0.5649709105491638\t Accuracy: 0.45248904824256897\n",
            "Step [696/882]\t Loss: 0.3155118525028229\t Accuracy: 0.5882015824317932\n",
            "Step [697/882]\t Loss: 0.3562202751636505\t Accuracy: 0.5083447694778442\n",
            "Step [698/882]\t Loss: 0.5323309302330017\t Accuracy: 0.45271170139312744\n",
            "Step [699/882]\t Loss: 0.28054577112197876\t Accuracy: 0.6013803482055664\n",
            "Step [700/882]\t Loss: 0.5181739330291748\t Accuracy: 0.45152443647384644\n",
            "Step [701/882]\t Loss: 0.32032713294029236\t Accuracy: 0.5779976844787598\n",
            "Step [702/882]\t Loss: 0.3926408588886261\t Accuracy: 0.5558087825775146\n",
            "Step [703/882]\t Loss: 0.5798083543777466\t Accuracy: 0.4569873809814453\n",
            "Step [704/882]\t Loss: 0.25764575600624084\t Accuracy: 0.6019085049629211\n",
            "Step [705/882]\t Loss: 0.3625083267688751\t Accuracy: 0.5054783821105957\n",
            "Step [706/882]\t Loss: 0.5419328212738037\t Accuracy: 0.3734780251979828\n",
            "Step [707/882]\t Loss: 0.48572880029678345\t Accuracy: 0.4687449038028717\n",
            "Step [708/882]\t Loss: 0.27140480279922485\t Accuracy: 0.6050372123718262\n",
            "Step [709/882]\t Loss: 0.356859028339386\t Accuracy: 0.4904400110244751\n",
            "Step [710/882]\t Loss: 0.26746055483818054\t Accuracy: 0.607361912727356\n",
            "Step [711/882]\t Loss: 0.2881925404071808\t Accuracy: 0.5941447019577026\n",
            "Step [712/882]\t Loss: 0.23470443487167358\t Accuracy: 0.6185661554336548\n",
            "Step [713/882]\t Loss: 0.518230140209198\t Accuracy: 0.46882280707359314\n",
            "Step [714/882]\t Loss: 0.24594227969646454\t Accuracy: 0.6385012269020081\n",
            "Step [715/882]\t Loss: 0.5083713531494141\t Accuracy: 0.46135738492012024\n",
            "Step [716/882]\t Loss: 0.3706277310848236\t Accuracy: 0.5185205936431885\n",
            "Step [717/882]\t Loss: 0.5396292805671692\t Accuracy: 0.49624231457710266\n",
            "Step [718/882]\t Loss: 0.2550208866596222\t Accuracy: 0.6247517466545105\n",
            "Step [719/882]\t Loss: 0.6157321333885193\t Accuracy: 0.5170337557792664\n",
            "Step [720/882]\t Loss: 0.6252077221870422\t Accuracy: 0.5123786926269531\n",
            "Step [721/882]\t Loss: 0.26469656825065613\t Accuracy: 0.6062034964561462\n",
            "Step [722/882]\t Loss: 0.2920404076576233\t Accuracy: 0.6027460098266602\n",
            "Step [723/882]\t Loss: 0.28463709354400635\t Accuracy: 0.6060134768486023\n",
            "Step [724/882]\t Loss: 0.3638198673725128\t Accuracy: 0.5830814838409424\n",
            "Step [725/882]\t Loss: 0.4542001485824585\t Accuracy: 0.5525856018066406\n",
            "Step [726/882]\t Loss: 0.2909989058971405\t Accuracy: 0.5857095718383789\n",
            "Step [727/882]\t Loss: 0.3348294496536255\t Accuracy: 0.5804489850997925\n",
            "Step [728/882]\t Loss: 0.39955592155456543\t Accuracy: 0.5667393803596497\n",
            "Step [729/882]\t Loss: 0.28165507316589355\t Accuracy: 0.6148969531059265\n",
            "Step [730/882]\t Loss: 0.480349600315094\t Accuracy: 0.4943963885307312\n",
            "Step [731/882]\t Loss: 0.18391770124435425\t Accuracy: 0.6623188853263855\n",
            "Step [732/882]\t Loss: 0.7028371095657349\t Accuracy: 0.42777320742607117\n",
            "Step [733/882]\t Loss: 0.3394266963005066\t Accuracy: 0.6020123958587646\n",
            "Step [734/882]\t Loss: 0.6827965378761292\t Accuracy: 0.370303213596344\n",
            "Step [735/882]\t Loss: 0.3094063997268677\t Accuracy: 0.6120801568031311\n",
            "Step [736/882]\t Loss: 0.483755499124527\t Accuracy: 0.548466682434082\n",
            "Step [737/882]\t Loss: 0.2408009171485901\t Accuracy: 0.6248410940170288\n",
            "Step [738/882]\t Loss: 0.7367020845413208\t Accuracy: 0.36440515518188477\n",
            "Step [739/882]\t Loss: 0.2944486141204834\t Accuracy: 0.5795660614967346\n",
            "Step [740/882]\t Loss: 0.4620111584663391\t Accuracy: 0.4604651927947998\n",
            "Step [741/882]\t Loss: 0.2938266396522522\t Accuracy: 0.5698812007904053\n",
            "Step [742/882]\t Loss: 0.42700013518333435\t Accuracy: 0.44626185297966003\n",
            "Step [743/882]\t Loss: 0.23693199455738068\t Accuracy: 0.5931599140167236\n",
            "Step [744/882]\t Loss: 0.45160624384880066\t Accuracy: 0.4647679924964905\n",
            "Step [745/882]\t Loss: 0.35671088099479675\t Accuracy: 0.5584574341773987\n",
            "Step [746/882]\t Loss: 0.3345550298690796\t Accuracy: 0.5091500282287598\n",
            "Step [747/882]\t Loss: 0.4000600278377533\t Accuracy: 0.48013100028038025\n",
            "Step [748/882]\t Loss: 0.3094823658466339\t Accuracy: 0.5908688306808472\n",
            "Step [749/882]\t Loss: 0.4068033695220947\t Accuracy: 0.5636376738548279\n",
            "Step [750/882]\t Loss: 0.4773687720298767\t Accuracy: 0.4827122688293457\n",
            "Step [751/882]\t Loss: 0.4483492970466614\t Accuracy: 0.5496293306350708\n",
            "Step [752/882]\t Loss: 0.2614060044288635\t Accuracy: 0.6358267068862915\n",
            "Step [753/882]\t Loss: 0.34353554248809814\t Accuracy: 0.5997810959815979\n",
            "Step [754/882]\t Loss: 0.25761878490448\t Accuracy: 0.6350282430648804\n",
            "Step [755/882]\t Loss: 0.3777359426021576\t Accuracy: 0.5203097462654114\n",
            "Step [756/882]\t Loss: 0.26784202456474304\t Accuracy: 0.6445915102958679\n",
            "Step [757/882]\t Loss: 0.3381969630718231\t Accuracy: 0.6129361391067505\n",
            "Step [758/882]\t Loss: 0.3866894543170929\t Accuracy: 0.549087405204773\n",
            "Step [759/882]\t Loss: 0.43829959630966187\t Accuracy: 0.5860546827316284\n",
            "Step [760/882]\t Loss: 0.39563989639282227\t Accuracy: 0.6001097559928894\n",
            "Step [761/882]\t Loss: 0.22635190188884735\t Accuracy: 0.6703524589538574\n",
            "Step [762/882]\t Loss: 0.4037061333656311\t Accuracy: 0.5111703276634216\n",
            "Step [763/882]\t Loss: 0.40429162979125977\t Accuracy: 0.5264075994491577\n",
            "Step [764/882]\t Loss: 0.2405475229024887\t Accuracy: 0.6601487398147583\n",
            "Step [765/882]\t Loss: 0.2087673544883728\t Accuracy: 0.6776595711708069\n",
            "Step [766/882]\t Loss: 0.38939589262008667\t Accuracy: 0.5933867692947388\n",
            "Step [767/882]\t Loss: 0.24683460593223572\t Accuracy: 0.6583342552185059\n",
            "Step [768/882]\t Loss: 0.251596063375473\t Accuracy: 0.6538568139076233\n",
            "Step [769/882]\t Loss: 0.28035762906074524\t Accuracy: 0.6531499028205872\n",
            "Step [770/882]\t Loss: 0.24994172155857086\t Accuracy: 0.6651742458343506\n",
            "Step [771/882]\t Loss: 0.16263337433338165\t Accuracy: 0.7051665186882019\n",
            "Step [772/882]\t Loss: 0.24453499913215637\t Accuracy: 0.6763289570808411\n",
            "Step [773/882]\t Loss: 0.4114336371421814\t Accuracy: 0.5506630539894104\n",
            "Step [774/882]\t Loss: 0.2602383494377136\t Accuracy: 0.6804359555244446\n",
            "Step [775/882]\t Loss: 0.4251399338245392\t Accuracy: 0.549580454826355\n",
            "Step [776/882]\t Loss: 0.2842240631580353\t Accuracy: 0.6742597818374634\n",
            "Step [777/882]\t Loss: 0.28464120626449585\t Accuracy: 0.6828718185424805\n",
            "Step [778/882]\t Loss: 0.41373974084854126\t Accuracy: 0.5468776822090149\n",
            "Step [779/882]\t Loss: 0.6210861206054688\t Accuracy: 0.48702070116996765\n",
            "Step [780/882]\t Loss: 0.4103113114833832\t Accuracy: 0.6158238053321838\n",
            "Step [781/882]\t Loss: 0.23380906879901886\t Accuracy: 0.6764843463897705\n",
            "Step [782/882]\t Loss: 0.2694052457809448\t Accuracy: 0.6444131135940552\n",
            "Step [783/882]\t Loss: 0.2824384570121765\t Accuracy: 0.6344484686851501\n",
            "Step [784/882]\t Loss: 0.6777858734130859\t Accuracy: 0.3848053216934204\n",
            "Step [785/882]\t Loss: 0.21968071162700653\t Accuracy: 0.6528163552284241\n",
            "Step [786/882]\t Loss: 0.3019673824310303\t Accuracy: 0.6097569465637207\n",
            "Step [787/882]\t Loss: 0.2428128570318222\t Accuracy: 0.632227897644043\n",
            "Step [788/882]\t Loss: 0.41246238350868225\t Accuracy: 0.565386176109314\n",
            "Step [789/882]\t Loss: 0.649671196937561\t Accuracy: 0.38344720005989075\n",
            "Step [790/882]\t Loss: 0.36379384994506836\t Accuracy: 0.5079785585403442\n",
            "Step [791/882]\t Loss: 0.43097347021102905\t Accuracy: 0.5360829830169678\n",
            "Step [792/882]\t Loss: 0.2617725431919098\t Accuracy: 0.610162615776062\n",
            "Step [793/882]\t Loss: 0.2639589011669159\t Accuracy: 0.6049875617027283\n",
            "Step [794/882]\t Loss: 0.3625205457210541\t Accuracy: 0.568306028842926\n",
            "Step [795/882]\t Loss: 0.4609123468399048\t Accuracy: 0.47270503640174866\n",
            "Step [796/882]\t Loss: 0.36846137046813965\t Accuracy: 0.5629388093948364\n",
            "Step [797/882]\t Loss: 0.445130854845047\t Accuracy: 0.5416251420974731\n",
            "Step [798/882]\t Loss: 0.3511788547039032\t Accuracy: 0.5674593448638916\n",
            "Step [799/882]\t Loss: 0.42051053047180176\t Accuracy: 0.49957969784736633\n",
            "Step [800/882]\t Loss: 0.26985985040664673\t Accuracy: 0.6132136583328247\n",
            "Step [801/882]\t Loss: 0.5457952618598938\t Accuracy: 0.4628714919090271\n",
            "Step [802/882]\t Loss: 0.2788517475128174\t Accuracy: 0.6077859997749329\n",
            "Step [803/882]\t Loss: 0.22414027154445648\t Accuracy: 0.6446231603622437\n",
            "Step [804/882]\t Loss: 0.35824814438819885\t Accuracy: 0.5918598771095276\n",
            "Step [805/882]\t Loss: 0.31241533160209656\t Accuracy: 0.6117700338363647\n",
            "Step [806/882]\t Loss: 0.20678286254405975\t Accuracy: 0.6682202816009521\n",
            "Step [807/882]\t Loss: 0.4771520793437958\t Accuracy: 0.49965882301330566\n",
            "Step [808/882]\t Loss: 0.4031233787536621\t Accuracy: 0.5993942022323608\n",
            "Step [809/882]\t Loss: 0.5500675439834595\t Accuracy: 0.49075788259506226\n",
            "Step [810/882]\t Loss: 0.35007768869400024\t Accuracy: 0.5506648421287537\n",
            "Step [811/882]\t Loss: 0.24289296567440033\t Accuracy: 0.6574887633323669\n",
            "Step [812/882]\t Loss: 0.5473187565803528\t Accuracy: 0.4731943905353546\n",
            "Step [813/882]\t Loss: 0.6271143555641174\t Accuracy: 0.46032825112342834\n",
            "Step [814/882]\t Loss: 0.21725349128246307\t Accuracy: 0.6576582193374634\n",
            "Step [815/882]\t Loss: 0.2806735634803772\t Accuracy: 0.6096815466880798\n",
            "Step [816/882]\t Loss: 0.22363273799419403\t Accuracy: 0.6327511668205261\n",
            "Step [817/882]\t Loss: 0.3732757270336151\t Accuracy: 0.5704395771026611\n",
            "Step [818/882]\t Loss: 0.3722268342971802\t Accuracy: 0.5086601972579956\n",
            "Step [819/882]\t Loss: 0.4692000448703766\t Accuracy: 0.4835669994354248\n",
            "Step [820/882]\t Loss: 0.40733370184898376\t Accuracy: 0.5599406957626343\n",
            "Step [821/882]\t Loss: 0.1915648877620697\t Accuracy: 0.656343936920166\n",
            "Step [822/882]\t Loss: 0.4006284177303314\t Accuracy: 0.5029630064964294\n",
            "Step [823/882]\t Loss: 0.5483009219169617\t Accuracy: 0.4543790817260742\n",
            "Step [824/882]\t Loss: 0.48349618911743164\t Accuracy: 0.4711975157260895\n",
            "Step [825/882]\t Loss: 0.44363144040107727\t Accuracy: 0.49071067571640015\n",
            "Step [826/882]\t Loss: 0.5477979779243469\t Accuracy: 0.4403368830680847\n",
            "Step [827/882]\t Loss: 0.4362179636955261\t Accuracy: 0.46718665957450867\n",
            "Step [828/882]\t Loss: 0.4256989657878876\t Accuracy: 0.5462517738342285\n",
            "Step [829/882]\t Loss: 0.23330087959766388\t Accuracy: 0.6039106845855713\n",
            "Step [830/882]\t Loss: 0.2321990430355072\t Accuracy: 0.600588321685791\n",
            "Step [831/882]\t Loss: 0.466463178396225\t Accuracy: 0.5364221334457397\n",
            "Step [832/882]\t Loss: 0.5281985998153687\t Accuracy: 0.46330735087394714\n",
            "Step [833/882]\t Loss: 0.3996611535549164\t Accuracy: 0.546994149684906\n",
            "Step [834/882]\t Loss: 0.2616439759731293\t Accuracy: 0.6030688881874084\n",
            "Step [835/882]\t Loss: 0.40565481781959534\t Accuracy: 0.49767959117889404\n",
            "Step [836/882]\t Loss: 0.391279399394989\t Accuracy: 0.49360278248786926\n",
            "Step [837/882]\t Loss: 0.31765317916870117\t Accuracy: 0.6005911231040955\n",
            "Step [838/882]\t Loss: 0.2587762773036957\t Accuracy: 0.622921347618103\n",
            "Step [839/882]\t Loss: 0.7252143621444702\t Accuracy: 0.34305545687675476\n",
            "Step [840/882]\t Loss: 0.40818583965301514\t Accuracy: 0.4872986674308777\n",
            "Step [841/882]\t Loss: 0.3224521577358246\t Accuracy: 0.5992764830589294\n",
            "Step [842/882]\t Loss: 0.3125939965248108\t Accuracy: 0.5267741084098816\n",
            "Step [843/882]\t Loss: 0.4292465150356293\t Accuracy: 0.4961308538913727\n",
            "Step [844/882]\t Loss: 0.3765166997909546\t Accuracy: 0.5058513879776001\n",
            "Step [845/882]\t Loss: 0.5175484418869019\t Accuracy: 0.531238317489624\n",
            "Step [846/882]\t Loss: 0.24784542620182037\t Accuracy: 0.6129688024520874\n",
            "Step [847/882]\t Loss: 0.34462669491767883\t Accuracy: 0.498543918132782\n",
            "Step [848/882]\t Loss: 0.21313725411891937\t Accuracy: 0.6238617897033691\n",
            "Step [849/882]\t Loss: 0.21629570424556732\t Accuracy: 0.6390649676322937\n",
            "Step [850/882]\t Loss: 0.4778696298599243\t Accuracy: 0.5304291844367981\n",
            "Step [851/882]\t Loss: 0.46168020367622375\t Accuracy: 0.5535439848899841\n",
            "Step [852/882]\t Loss: 0.46285873651504517\t Accuracy: 0.49090173840522766\n",
            "Step [853/882]\t Loss: 0.3746809959411621\t Accuracy: 0.5716511607170105\n",
            "Step [854/882]\t Loss: 0.27849942445755005\t Accuracy: 0.6339796781539917\n",
            "Step [855/882]\t Loss: 0.3797076642513275\t Accuracy: 0.5142046809196472\n",
            "Step [856/882]\t Loss: 0.24408984184265137\t Accuracy: 0.6367059350013733\n",
            "Step [857/882]\t Loss: 0.19462470710277557\t Accuracy: 0.6749752163887024\n",
            "Step [858/882]\t Loss: 0.44684773683547974\t Accuracy: 0.5687843561172485\n",
            "Step [859/882]\t Loss: 0.37758171558380127\t Accuracy: 0.5275865793228149\n",
            "Step [860/882]\t Loss: 0.36893323063850403\t Accuracy: 0.6042495369911194\n",
            "Step [861/882]\t Loss: 0.38932499289512634\t Accuracy: 0.5215957164764404\n",
            "Step [862/882]\t Loss: 0.19705891609191895\t Accuracy: 0.6789678335189819\n",
            "Step [863/882]\t Loss: 0.43454989790916443\t Accuracy: 0.5708687901496887\n",
            "Step [864/882]\t Loss: 0.3674929738044739\t Accuracy: 0.5984528660774231\n",
            "Step [865/882]\t Loss: 0.21086251735687256\t Accuracy: 0.6763103604316711\n",
            "Step [866/882]\t Loss: 0.40841203927993774\t Accuracy: 0.5305913686752319\n",
            "Step [867/882]\t Loss: 0.3079119026660919\t Accuracy: 0.612694501876831\n",
            "Step [868/882]\t Loss: 0.2573447525501251\t Accuracy: 0.651644229888916\n",
            "Step [869/882]\t Loss: 0.6130453944206238\t Accuracy: 0.5246027708053589\n",
            "Step [870/882]\t Loss: 0.16829083859920502\t Accuracy: 0.6885486841201782\n",
            "Step [871/882]\t Loss: 0.5261814594268799\t Accuracy: 0.47626712918281555\n",
            "Step [872/882]\t Loss: 0.6830970048904419\t Accuracy: 0.38916006684303284\n",
            "Step [873/882]\t Loss: 0.46195149421691895\t Accuracy: 0.4821186065673828\n",
            "Step [874/882]\t Loss: 0.38161030411720276\t Accuracy: 0.4936501979827881\n",
            "Step [875/882]\t Loss: 0.29584646224975586\t Accuracy: 0.5898459553718567\n",
            "Step [876/882]\t Loss: 0.5739343762397766\t Accuracy: 0.354501873254776\n",
            "Step [877/882]\t Loss: 0.44425830245018005\t Accuracy: 0.48393043875694275\n",
            "Step [878/882]\t Loss: 0.36746513843536377\t Accuracy: 0.5390132069587708\n",
            "Step [879/882]\t Loss: 0.48617058992385864\t Accuracy: 0.42695289850234985\n",
            "Step [880/882]\t Loss: 0.3261420726776123\t Accuracy: 0.5436593890190125\n",
            "Step [881/882]\t Loss: 0.541479229927063\t Accuracy: 0.44228503108024597\n",
            "Epoch [0/2]\t Loss: 0.3965540932081724\t Accuracy: 0.5457228422164917\n",
            "Step [0/882]\t Loss: 0.5604467391967773\t Accuracy: 0.42825448513031006\n",
            "Step [1/882]\t Loss: 0.45523801445961\t Accuracy: 0.4637829661369324\n",
            "Step [2/882]\t Loss: 0.3986416459083557\t Accuracy: 0.46019041538238525\n",
            "Step [3/882]\t Loss: 0.28131937980651855\t Accuracy: 0.5544254183769226\n",
            "Step [4/882]\t Loss: 0.5151524543762207\t Accuracy: 0.3603486716747284\n",
            "Step [5/882]\t Loss: 0.4357123076915741\t Accuracy: 0.5153031349182129\n",
            "Step [6/882]\t Loss: 0.3840427100658417\t Accuracy: 0.5285964608192444\n",
            "Step [7/882]\t Loss: 0.3086191713809967\t Accuracy: 0.568601131439209\n",
            "Step [8/882]\t Loss: 0.3320762515068054\t Accuracy: 0.5065197944641113\n",
            "Step [9/882]\t Loss: 0.5190992951393127\t Accuracy: 0.4544267952442169\n",
            "Step [10/882]\t Loss: 0.25809985399246216\t Accuracy: 0.6152709722518921\n",
            "Step [11/882]\t Loss: 0.21852479875087738\t Accuracy: 0.6360845565795898\n",
            "Step [12/882]\t Loss: 0.453447550535202\t Accuracy: 0.495413601398468\n",
            "Step [13/882]\t Loss: 0.4438728392124176\t Accuracy: 0.5056081414222717\n",
            "Step [14/882]\t Loss: 0.2407466322183609\t Accuracy: 0.6510857939720154\n",
            "Step [15/882]\t Loss: 0.44267895817756653\t Accuracy: 0.5728854537010193\n",
            "Step [16/882]\t Loss: 0.30992335081100464\t Accuracy: 0.5582467317581177\n",
            "Step [17/882]\t Loss: 0.16338220238685608\t Accuracy: 0.6971077919006348\n",
            "Step [18/882]\t Loss: 0.30859383940696716\t Accuracy: 0.6260057091712952\n",
            "Step [19/882]\t Loss: 0.2368503361940384\t Accuracy: 0.6534038186073303\n",
            "Step [20/882]\t Loss: 0.3965435326099396\t Accuracy: 0.5857054591178894\n",
            "Step [21/882]\t Loss: 0.33609965443611145\t Accuracy: 0.6239243149757385\n",
            "Step [22/882]\t Loss: 0.3478243052959442\t Accuracy: 0.6250869035720825\n",
            "Step [23/882]\t Loss: 0.3595151901245117\t Accuracy: 0.6291218400001526\n",
            "Step [24/882]\t Loss: 0.5143569111824036\t Accuracy: 0.5802069306373596\n",
            "Step [25/882]\t Loss: 0.27522942423820496\t Accuracy: 0.6484944820404053\n",
            "Step [26/882]\t Loss: 0.2659497857093811\t Accuracy: 0.6462420225143433\n",
            "Step [27/882]\t Loss: 0.3456951975822449\t Accuracy: 0.6055502891540527\n",
            "Step [28/882]\t Loss: 0.3373556137084961\t Accuracy: 0.6160624623298645\n",
            "Step [29/882]\t Loss: 0.2888685464859009\t Accuracy: 0.6284993290901184\n",
            "Step [30/882]\t Loss: 0.39022329449653625\t Accuracy: 0.5096051096916199\n",
            "Step [31/882]\t Loss: 0.5024936199188232\t Accuracy: 0.4921775460243225\n",
            "Step [32/882]\t Loss: 0.22004418075084686\t Accuracy: 0.6576911807060242\n",
            "Step [33/882]\t Loss: 0.3056424856185913\t Accuracy: 0.6081658601760864\n",
            "Step [34/882]\t Loss: 0.3363714814186096\t Accuracy: 0.5968914031982422\n",
            "Step [35/882]\t Loss: 0.4075360596179962\t Accuracy: 0.5107876062393188\n",
            "Step [36/882]\t Loss: 0.7482780814170837\t Accuracy: 0.3558897078037262\n",
            "Step [37/882]\t Loss: 0.4746195077896118\t Accuracy: 0.5488448739051819\n",
            "Step [38/882]\t Loss: 0.22490233182907104\t Accuracy: 0.6287394762039185\n",
            "Step [39/882]\t Loss: 0.21372763812541962\t Accuracy: 0.6412133574485779\n",
            "Step [40/882]\t Loss: 0.33911192417144775\t Accuracy: 0.5810999870300293\n",
            "Step [41/882]\t Loss: 0.4689403176307678\t Accuracy: 0.5157783627510071\n",
            "Step [42/882]\t Loss: 0.5232837796211243\t Accuracy: 0.373331218957901\n",
            "Step [43/882]\t Loss: 0.31377771496772766\t Accuracy: 0.5863446593284607\n",
            "Step [44/882]\t Loss: 0.40783658623695374\t Accuracy: 0.5560012459754944\n",
            "Step [45/882]\t Loss: 0.24376320838928223\t Accuracy: 0.6083807349205017\n",
            "Step [46/882]\t Loss: 0.35456517338752747\t Accuracy: 0.5809049010276794\n",
            "Step [47/882]\t Loss: 0.307900995016098\t Accuracy: 0.6057910323143005\n",
            "Step [48/882]\t Loss: 0.4069046080112457\t Accuracy: 0.5012446641921997\n",
            "Step [49/882]\t Loss: 0.6419349312782288\t Accuracy: 0.44542601704597473\n",
            "Step [50/882]\t Loss: 0.42792460322380066\t Accuracy: 0.49566948413848877\n",
            "Step [51/882]\t Loss: 0.2725386917591095\t Accuracy: 0.6311032772064209\n",
            "Step [52/882]\t Loss: 0.32165125012397766\t Accuracy: 0.6085797548294067\n",
            "Step [53/882]\t Loss: 0.48078256845474243\t Accuracy: 0.47297224402427673\n",
            "Step [54/882]\t Loss: 0.41130301356315613\t Accuracy: 0.5705568790435791\n",
            "Step [55/882]\t Loss: 0.5428934693336487\t Accuracy: 0.45468589663505554\n",
            "Step [56/882]\t Loss: 0.2984906733036041\t Accuracy: 0.5836430191993713\n",
            "Step [57/882]\t Loss: 0.4493914842605591\t Accuracy: 0.4682326316833496\n",
            "Step [58/882]\t Loss: 0.34462693333625793\t Accuracy: 0.5544637441635132\n",
            "Step [59/882]\t Loss: 0.5028831362724304\t Accuracy: 0.45966479182243347\n",
            "Step [60/882]\t Loss: 0.3982195556163788\t Accuracy: 0.5412300229072571\n",
            "Step [61/882]\t Loss: 0.33131441473960876\t Accuracy: 0.5578737854957581\n",
            "Step [62/882]\t Loss: 0.3603900671005249\t Accuracy: 0.5608312487602234\n",
            "Step [63/882]\t Loss: 0.3247874081134796\t Accuracy: 0.5808560848236084\n",
            "Step [64/882]\t Loss: 0.3891870081424713\t Accuracy: 0.49421751499176025\n",
            "Step [65/882]\t Loss: 0.4447072148323059\t Accuracy: 0.4684629738330841\n",
            "Step [66/882]\t Loss: 0.5202065110206604\t Accuracy: 0.43581557273864746\n",
            "Step [67/882]\t Loss: 0.4151504635810852\t Accuracy: 0.48381307721138\n",
            "Step [68/882]\t Loss: 0.5511290431022644\t Accuracy: 0.4504261910915375\n",
            "Step [69/882]\t Loss: 0.24143677949905396\t Accuracy: 0.6241621375083923\n",
            "Step [70/882]\t Loss: 0.5018274784088135\t Accuracy: 0.48614075779914856\n",
            "Step [71/882]\t Loss: 0.3721427321434021\t Accuracy: 0.4957210123538971\n",
            "Step [72/882]\t Loss: 0.683778703212738\t Accuracy: 0.36914151906967163\n",
            "Step [73/882]\t Loss: 0.5376487970352173\t Accuracy: 0.4408210217952728\n",
            "Step [74/882]\t Loss: 0.4285304546356201\t Accuracy: 0.45974400639533997\n",
            "Step [75/882]\t Loss: 0.39514243602752686\t Accuracy: 0.4604220688343048\n",
            "Step [76/882]\t Loss: 0.4096646308898926\t Accuracy: 0.5137104392051697\n",
            "Step [77/882]\t Loss: 0.3416177034378052\t Accuracy: 0.5316117405891418\n",
            "Step [78/882]\t Loss: 0.47217699885368347\t Accuracy: 0.5051315426826477\n",
            "Step [79/882]\t Loss: 0.29866528511047363\t Accuracy: 0.5591051578521729\n",
            "Step [80/882]\t Loss: 0.37631332874298096\t Accuracy: 0.5393791794776917\n",
            "Step [81/882]\t Loss: 0.347003310918808\t Accuracy: 0.5529630780220032\n",
            "Step [82/882]\t Loss: 0.43047845363616943\t Accuracy: 0.529055655002594\n",
            "Step [83/882]\t Loss: 0.41143056750297546\t Accuracy: 0.47648170590400696\n",
            "Step [84/882]\t Loss: 0.2938762903213501\t Accuracy: 0.6032650470733643\n",
            "Step [85/882]\t Loss: 0.2289678454399109\t Accuracy: 0.6415631175041199\n",
            "Step [86/882]\t Loss: 0.261018842458725\t Accuracy: 0.6328287124633789\n",
            "Step [87/882]\t Loss: 0.32543227076530457\t Accuracy: 0.5473307967185974\n",
            "Step [88/882]\t Loss: 0.39451679587364197\t Accuracy: 0.5244055986404419\n",
            "Step [89/882]\t Loss: 0.20437775552272797\t Accuracy: 0.6851739883422852\n",
            "Step [90/882]\t Loss: 0.2816998362541199\t Accuracy: 0.6420560479164124\n",
            "Step [91/882]\t Loss: 0.22834999859333038\t Accuracy: 0.6890299320220947\n",
            "Step [92/882]\t Loss: 0.1762733906507492\t Accuracy: 0.7181476354598999\n",
            "Step [93/882]\t Loss: 0.49280843138694763\t Accuracy: 0.6147153377532959\n",
            "Step [94/882]\t Loss: 0.3832448720932007\t Accuracy: 0.6468102931976318\n",
            "Step [95/882]\t Loss: 0.3359528183937073\t Accuracy: 0.6803495287895203\n",
            "Step [96/882]\t Loss: 0.36536917090415955\t Accuracy: 0.5762044191360474\n",
            "Step [97/882]\t Loss: 0.9206462502479553\t Accuracy: 0.3656727075576782\n",
            "Step [98/882]\t Loss: 0.4157443344593048\t Accuracy: 0.5525456070899963\n",
            "Step [99/882]\t Loss: 0.40833309292793274\t Accuracy: 0.5858848094940186\n",
            "Step [100/882]\t Loss: 0.6305156946182251\t Accuracy: 0.3525441586971283\n",
            "Step [101/882]\t Loss: 0.2740137577056885\t Accuracy: 0.5807133913040161\n",
            "Step [102/882]\t Loss: 0.27298974990844727\t Accuracy: 0.5692132711410522\n",
            "Step [103/882]\t Loss: 0.300662636756897\t Accuracy: 0.5478929877281189\n",
            "Step [104/882]\t Loss: 0.35469940304756165\t Accuracy: 0.5269827246665955\n",
            "Step [105/882]\t Loss: 0.2667483687400818\t Accuracy: 0.5785529017448425\n",
            "Step [106/882]\t Loss: 0.5838219523429871\t Accuracy: 0.36486876010894775\n",
            "Step [107/882]\t Loss: 0.230233296751976\t Accuracy: 0.6202905178070068\n",
            "Step [108/882]\t Loss: 0.20907506346702576\t Accuracy: 0.6457943320274353\n",
            "Step [109/882]\t Loss: 0.34837788343429565\t Accuracy: 0.5912206768989563\n",
            "Step [110/882]\t Loss: 0.538573145866394\t Accuracy: 0.39701002836227417\n",
            "Step [111/882]\t Loss: 0.40452292561531067\t Accuracy: 0.5173664093017578\n",
            "Step [112/882]\t Loss: 0.4067533016204834\t Accuracy: 0.6002736687660217\n",
            "Step [113/882]\t Loss: 0.20729942619800568\t Accuracy: 0.672584056854248\n",
            "Step [114/882]\t Loss: 0.1409081071615219\t Accuracy: 0.7067365050315857\n",
            "Step [115/882]\t Loss: 0.46167537569999695\t Accuracy: 0.5099095702171326\n",
            "Step [116/882]\t Loss: 0.464236855506897\t Accuracy: 0.4988308250904083\n",
            "Step [117/882]\t Loss: 0.18320058286190033\t Accuracy: 0.6806351542472839\n",
            "Step [118/882]\t Loss: 0.7182347178459167\t Accuracy: 0.4551663100719452\n",
            "Step [119/882]\t Loss: 0.1894799768924713\t Accuracy: 0.6697990298271179\n",
            "Step [120/882]\t Loss: 0.4731369912624359\t Accuracy: 0.555202841758728\n",
            "Step [121/882]\t Loss: 0.3550499677658081\t Accuracy: 0.5824502110481262\n",
            "Step [122/882]\t Loss: 0.35818198323249817\t Accuracy: 0.5770740509033203\n",
            "Step [123/882]\t Loss: 0.2703346014022827\t Accuracy: 0.5913227796554565\n",
            "Step [124/882]\t Loss: 0.4408707320690155\t Accuracy: 0.5522400140762329\n",
            "Step [125/882]\t Loss: 0.5684612393379211\t Accuracy: 0.5126367807388306\n",
            "Step [126/882]\t Loss: 0.7056177258491516\t Accuracy: 0.369092732667923\n",
            "Step [127/882]\t Loss: 0.33470970392227173\t Accuracy: 0.5650011301040649\n",
            "Step [128/882]\t Loss: 0.5901176929473877\t Accuracy: 0.4294986128807068\n",
            "Step [129/882]\t Loss: 0.3746878206729889\t Accuracy: 0.5251695513725281\n",
            "Step [130/882]\t Loss: 0.3906213641166687\t Accuracy: 0.4524497389793396\n",
            "Step [131/882]\t Loss: 0.3408542573451996\t Accuracy: 0.5165786147117615\n",
            "Step [132/882]\t Loss: 0.4363879859447479\t Accuracy: 0.4413316249847412\n",
            "Step [133/882]\t Loss: 0.6448397040367126\t Accuracy: 0.3473060131072998\n",
            "Step [134/882]\t Loss: 0.3016526401042938\t Accuracy: 0.5712906122207642\n",
            "Step [135/882]\t Loss: 0.3285101652145386\t Accuracy: 0.5695517659187317\n",
            "Step [136/882]\t Loss: 0.49466240406036377\t Accuracy: 0.5219030380249023\n",
            "Step [137/882]\t Loss: 0.3364966809749603\t Accuracy: 0.5785183906555176\n",
            "Step [138/882]\t Loss: 0.29762589931488037\t Accuracy: 0.5965552926063538\n",
            "Step [139/882]\t Loss: 0.4322129786014557\t Accuracy: 0.5556946396827698\n",
            "Step [140/882]\t Loss: 0.3799542486667633\t Accuracy: 0.4952433705329895\n",
            "Step [141/882]\t Loss: 0.33709341287612915\t Accuracy: 0.600568950176239\n",
            "Step [142/882]\t Loss: 0.3179541230201721\t Accuracy: 0.5989141464233398\n",
            "Step [143/882]\t Loss: 0.2172890603542328\t Accuracy: 0.6619234681129456\n",
            "Step [144/882]\t Loss: 0.1953245848417282\t Accuracy: 0.6768683195114136\n",
            "Step [145/882]\t Loss: 0.42455407977104187\t Accuracy: 0.527915894985199\n",
            "Step [146/882]\t Loss: 0.28441494703292847\t Accuracy: 0.6404711604118347\n",
            "Step [147/882]\t Loss: 0.3035615086555481\t Accuracy: 0.6593421697616577\n",
            "Step [148/882]\t Loss: 0.25098469853401184\t Accuracy: 0.6717660427093506\n",
            "Step [149/882]\t Loss: 0.5264574885368347\t Accuracy: 0.5078948736190796\n",
            "Step [150/882]\t Loss: 0.3894738554954529\t Accuracy: 0.5847853422164917\n",
            "Step [151/882]\t Loss: 0.5480495691299438\t Accuracy: 0.505519449710846\n",
            "Step [152/882]\t Loss: 0.3746946156024933\t Accuracy: 0.5454069375991821\n",
            "Step [153/882]\t Loss: 0.5003082752227783\t Accuracy: 0.49478772282600403\n",
            "Step [154/882]\t Loss: 0.3748593032360077\t Accuracy: 0.5323664546012878\n",
            "Step [155/882]\t Loss: 0.4445016384124756\t Accuracy: 0.5613362789154053\n",
            "Step [156/882]\t Loss: 0.42485395073890686\t Accuracy: 0.5548123121261597\n",
            "Step [157/882]\t Loss: 0.2663368582725525\t Accuracy: 0.6026573777198792\n",
            "Step [158/882]\t Loss: 0.300687700510025\t Accuracy: 0.5846115350723267\n",
            "Step [159/882]\t Loss: 0.3837215304374695\t Accuracy: 0.48436933755874634\n",
            "Step [160/882]\t Loss: 0.4034801125526428\t Accuracy: 0.4882318079471588\n",
            "Step [161/882]\t Loss: 0.3838733732700348\t Accuracy: 0.5564892888069153\n",
            "Step [162/882]\t Loss: 0.2619931101799011\t Accuracy: 0.5956107974052429\n",
            "Step [163/882]\t Loss: 0.4173058867454529\t Accuracy: 0.48417142033576965\n",
            "Step [164/882]\t Loss: 0.3377782106399536\t Accuracy: 0.5868062376976013\n",
            "Step [165/882]\t Loss: 0.3596123158931732\t Accuracy: 0.4952872693538666\n",
            "Step [166/882]\t Loss: 0.5326492786407471\t Accuracy: 0.35480645298957825\n",
            "Step [167/882]\t Loss: 0.3923030197620392\t Accuracy: 0.5708091855049133\n",
            "Step [168/882]\t Loss: 0.22105512022972107\t Accuracy: 0.6340405344963074\n",
            "Step [169/882]\t Loss: 0.343666136264801\t Accuracy: 0.5966153144836426\n",
            "Step [170/882]\t Loss: 0.36121708154678345\t Accuracy: 0.5964258313179016\n",
            "Step [171/882]\t Loss: 0.37591221928596497\t Accuracy: 0.5394032597541809\n",
            "Step [172/882]\t Loss: 0.31719833612442017\t Accuracy: 0.5475625395774841\n",
            "Step [173/882]\t Loss: 0.3863571584224701\t Accuracy: 0.5198312401771545\n",
            "Step [174/882]\t Loss: 0.3547039330005646\t Accuracy: 0.6033746600151062\n",
            "Step [175/882]\t Loss: 0.3111777901649475\t Accuracy: 0.6229657530784607\n",
            "Step [176/882]\t Loss: 0.3974323570728302\t Accuracy: 0.5891017317771912\n",
            "Step [177/882]\t Loss: 0.2933996319770813\t Accuracy: 0.6252657771110535\n",
            "Step [178/882]\t Loss: 0.5714343786239624\t Accuracy: 0.46994665265083313\n",
            "Step [179/882]\t Loss: 0.37644898891448975\t Accuracy: 0.5797654390335083\n",
            "Step [180/882]\t Loss: 0.38275131583213806\t Accuracy: 0.5067326426506042\n",
            "Step [181/882]\t Loss: 0.5678975582122803\t Accuracy: 0.3825831711292267\n",
            "Step [182/882]\t Loss: 0.35007035732269287\t Accuracy: 0.5796104669570923\n",
            "Step [183/882]\t Loss: 0.18471769988536835\t Accuracy: 0.6517114639282227\n",
            "Step [184/882]\t Loss: 0.2989541292190552\t Accuracy: 0.5974811911582947\n",
            "Step [185/882]\t Loss: 0.45936957001686096\t Accuracy: 0.48412424325942993\n",
            "Step [186/882]\t Loss: 0.5443476438522339\t Accuracy: 0.450930655002594\n",
            "Step [187/882]\t Loss: 0.3670761287212372\t Accuracy: 0.5685988664627075\n",
            "Step [188/882]\t Loss: 0.29550692439079285\t Accuracy: 0.583385705947876\n",
            "Step [189/882]\t Loss: 0.6580290794372559\t Accuracy: 0.36125698685646057\n",
            "Step [190/882]\t Loss: 0.2379920780658722\t Accuracy: 0.6169612407684326\n",
            "Step [191/882]\t Loss: 0.36703959107398987\t Accuracy: 0.5554036498069763\n",
            "Step [192/882]\t Loss: 0.28828543424606323\t Accuracy: 0.5869825482368469\n",
            "Step [193/882]\t Loss: 0.2974097728729248\t Accuracy: 0.5827717781066895\n",
            "Step [194/882]\t Loss: 0.32192176580429077\t Accuracy: 0.5855022072792053\n",
            "Step [195/882]\t Loss: 0.35428178310394287\t Accuracy: 0.5839048624038696\n",
            "Step [196/882]\t Loss: 0.2899128198623657\t Accuracy: 0.603369951248169\n",
            "Step [197/882]\t Loss: 0.40215539932250977\t Accuracy: 0.5150514245033264\n",
            "Step [198/882]\t Loss: 0.40894028544425964\t Accuracy: 0.5126455426216125\n",
            "Step [199/882]\t Loss: 0.33502599596977234\t Accuracy: 0.5225916504859924\n",
            "Step [200/882]\t Loss: 0.37841448187828064\t Accuracy: 0.5171785354614258\n",
            "Step [201/882]\t Loss: 0.26860693097114563\t Accuracy: 0.6297962665557861\n",
            "Step [202/882]\t Loss: 0.2540122866630554\t Accuracy: 0.6503987312316895\n",
            "Step [203/882]\t Loss: 0.5649279952049255\t Accuracy: 0.5429971218109131\n",
            "Step [204/882]\t Loss: 0.4352407157421112\t Accuracy: 0.5810160040855408\n",
            "Step [205/882]\t Loss: 0.28365522623062134\t Accuracy: 0.6348932981491089\n",
            "Step [206/882]\t Loss: 0.4723207354545593\t Accuracy: 0.4978313148021698\n",
            "Step [207/882]\t Loss: 0.33005502820014954\t Accuracy: 0.5967954397201538\n",
            "Step [208/882]\t Loss: 0.5989801287651062\t Accuracy: 0.5213279724121094\n",
            "Step [209/882]\t Loss: 0.33232244849205017\t Accuracy: 0.6048071980476379\n",
            "Step [210/882]\t Loss: 0.25858771800994873\t Accuracy: 0.6283228993415833\n",
            "Step [211/882]\t Loss: 0.3016332685947418\t Accuracy: 0.6067177057266235\n",
            "Step [212/882]\t Loss: 0.43355366587638855\t Accuracy: 0.4903053045272827\n",
            "Step [213/882]\t Loss: 0.3928552567958832\t Accuracy: 0.5612360239028931\n",
            "Step [214/882]\t Loss: 0.28671014308929443\t Accuracy: 0.606130838394165\n",
            "Step [215/882]\t Loss: 0.5418416857719421\t Accuracy: 0.4678369164466858\n",
            "Step [216/882]\t Loss: 0.33194398880004883\t Accuracy: 0.5817168951034546\n",
            "Step [217/882]\t Loss: 0.27811509370803833\t Accuracy: 0.5983001589775085\n",
            "Step [218/882]\t Loss: 0.1964763104915619\t Accuracy: 0.6420921087265015\n",
            "Step [219/882]\t Loss: 0.6196861863136292\t Accuracy: 0.3506358861923218\n",
            "Step [220/882]\t Loss: 0.18809261918067932\t Accuracy: 0.6571633219718933\n",
            "Step [221/882]\t Loss: 0.3179914951324463\t Accuracy: 0.5957244038581848\n",
            "Step [222/882]\t Loss: 0.3030019998550415\t Accuracy: 0.6144407391548157\n",
            "Step [223/882]\t Loss: 0.20422837138175964\t Accuracy: 0.6653540730476379\n",
            "Step [224/882]\t Loss: 0.1913510113954544\t Accuracy: 0.6716836094856262\n",
            "Step [225/882]\t Loss: 0.314390629529953\t Accuracy: 0.6301162838935852\n",
            "Step [226/882]\t Loss: 0.4757828116416931\t Accuracy: 0.5792182087898254\n",
            "Step [227/882]\t Loss: 0.3906131684780121\t Accuracy: 0.6173118352890015\n",
            "Step [228/882]\t Loss: 0.16442568600177765\t Accuracy: 0.714227557182312\n",
            "Step [229/882]\t Loss: 0.1929086446762085\t Accuracy: 0.7163738012313843\n",
            "Step [230/882]\t Loss: 0.6957546472549438\t Accuracy: 0.46474719047546387\n",
            "Step [231/882]\t Loss: 0.5721330642700195\t Accuracy: 0.4971639811992645\n",
            "Step [232/882]\t Loss: 0.45201170444488525\t Accuracy: 0.5270276069641113\n",
            "Step [233/882]\t Loss: 0.21350321173667908\t Accuracy: 0.6895654797554016\n",
            "Step [234/882]\t Loss: 0.5182725191116333\t Accuracy: 0.48842406272888184\n",
            "Step [235/882]\t Loss: 0.37563440203666687\t Accuracy: 0.6002113223075867\n",
            "Step [236/882]\t Loss: 0.6112362146377563\t Accuracy: 0.36708196997642517\n",
            "Step [237/882]\t Loss: 0.39303064346313477\t Accuracy: 0.5700380802154541\n",
            "Step [238/882]\t Loss: 0.25032880902290344\t Accuracy: 0.621269166469574\n",
            "Step [239/882]\t Loss: 0.32659468054771423\t Accuracy: 0.5849551558494568\n",
            "Step [240/882]\t Loss: 0.25275087356567383\t Accuracy: 0.599197268486023\n",
            "Step [241/882]\t Loss: 0.47717028856277466\t Accuracy: 0.4516758918762207\n",
            "Step [242/882]\t Loss: 0.34004291892051697\t Accuracy: 0.5759790539741516\n",
            "Step [243/882]\t Loss: 0.2523714303970337\t Accuracy: 0.6102333664894104\n",
            "Step [244/882]\t Loss: 0.5160558819770813\t Accuracy: 0.46100568771362305\n",
            "Step [245/882]\t Loss: 0.35207220911979675\t Accuracy: 0.519639790058136\n",
            "Step [246/882]\t Loss: 0.5282498598098755\t Accuracy: 0.45339372754096985\n",
            "Step [247/882]\t Loss: 0.42048412561416626\t Accuracy: 0.547105610370636\n",
            "Step [248/882]\t Loss: 0.3682885766029358\t Accuracy: 0.5116243362426758\n",
            "Step [249/882]\t Loss: 0.47667279839515686\t Accuracy: 0.46503517031669617\n",
            "Step [250/882]\t Loss: 0.3890226185321808\t Accuracy: 0.48556485772132874\n",
            "Step [251/882]\t Loss: 0.4964486062526703\t Accuracy: 0.4883933365345001\n",
            "Step [252/882]\t Loss: 0.5693716406822205\t Accuracy: 0.372424840927124\n",
            "Step [253/882]\t Loss: 0.3736908435821533\t Accuracy: 0.5288099646568298\n",
            "Step [254/882]\t Loss: 0.4133848547935486\t Accuracy: 0.546231210231781\n",
            "Step [255/882]\t Loss: 0.3679869472980499\t Accuracy: 0.49657121300697327\n",
            "Step [256/882]\t Loss: 0.32317274808883667\t Accuracy: 0.5714327096939087\n",
            "Step [257/882]\t Loss: 0.5214917063713074\t Accuracy: 0.5086851716041565\n",
            "Step [258/882]\t Loss: 0.42548367381095886\t Accuracy: 0.46963968873023987\n",
            "Step [259/882]\t Loss: 0.4788382649421692\t Accuracy: 0.4526478052139282\n",
            "Step [260/882]\t Loss: 0.48367929458618164\t Accuracy: 0.5170873999595642\n",
            "Step [261/882]\t Loss: 0.31656479835510254\t Accuracy: 0.5588605403900146\n",
            "Step [262/882]\t Loss: 0.3440970480442047\t Accuracy: 0.5596649646759033\n",
            "Step [263/882]\t Loss: 0.3715499937534332\t Accuracy: 0.4915129840373993\n",
            "Step [264/882]\t Loss: 0.3484865725040436\t Accuracy: 0.5584513545036316\n",
            "Step [265/882]\t Loss: 0.674256443977356\t Accuracy: 0.48186758160591125\n",
            "Step [266/882]\t Loss: 0.38541629910469055\t Accuracy: 0.512559711933136\n",
            "Step [267/882]\t Loss: 0.20103134214878082\t Accuracy: 0.6349048018455505\n",
            "Step [268/882]\t Loss: 0.36979940533638\t Accuracy: 0.5700938701629639\n",
            "Step [269/882]\t Loss: 0.405139684677124\t Accuracy: 0.5683188438415527\n",
            "Step [270/882]\t Loss: 0.4033219516277313\t Accuracy: 0.4976767301559448\n",
            "Step [271/882]\t Loss: 0.3239996135234833\t Accuracy: 0.597706139087677\n",
            "Step [272/882]\t Loss: 0.3637699484825134\t Accuracy: 0.5139455795288086\n",
            "Step [273/882]\t Loss: 0.3674365282058716\t Accuracy: 0.5183337330818176\n",
            "Step [274/882]\t Loss: 0.19482062757015228\t Accuracy: 0.6697934865951538\n",
            "Step [275/882]\t Loss: 0.27705517411231995\t Accuracy: 0.6277714967727661\n",
            "Step [276/882]\t Loss: 0.4635460674762726\t Accuracy: 0.5032739043235779\n",
            "Step [277/882]\t Loss: 0.3629586696624756\t Accuracy: 0.6180159449577332\n",
            "Step [278/882]\t Loss: 0.3592362403869629\t Accuracy: 0.6210163235664368\n",
            "Step [279/882]\t Loss: 0.14417609572410583\t Accuracy: 0.7213693261146545\n",
            "Step [280/882]\t Loss: 0.24100558459758759\t Accuracy: 0.6582052707672119\n",
            "Step [281/882]\t Loss: 0.19458389282226562\t Accuracy: 0.6944398880004883\n",
            "Step [282/882]\t Loss: 0.17802727222442627\t Accuracy: 0.718320369720459\n",
            "Step [283/882]\t Loss: 0.40798255801200867\t Accuracy: 0.571095883846283\n",
            "Step [284/882]\t Loss: 0.46798694133758545\t Accuracy: 0.6189926266670227\n",
            "Step [285/882]\t Loss: 0.18976503610610962\t Accuracy: 0.731857180595398\n",
            "Step [286/882]\t Loss: 0.24814486503601074\t Accuracy: 0.701686680316925\n",
            "Step [287/882]\t Loss: 0.1954207420349121\t Accuracy: 0.7123733162879944\n",
            "Step [288/882]\t Loss: 0.30919575691223145\t Accuracy: 0.6882908940315247\n",
            "Step [289/882]\t Loss: 0.4110538959503174\t Accuracy: 0.6376835703849792\n",
            "Step [290/882]\t Loss: 0.5584695339202881\t Accuracy: 0.5121275782585144\n",
            "Step [291/882]\t Loss: 0.25963500142097473\t Accuracy: 0.6736545562744141\n",
            "Step [292/882]\t Loss: 0.1403026580810547\t Accuracy: 0.7351744174957275\n",
            "Step [293/882]\t Loss: 0.49660828709602356\t Accuracy: 0.4991879463195801\n",
            "Step [294/882]\t Loss: 0.2787022292613983\t Accuracy: 0.6618974804878235\n",
            "Step [295/882]\t Loss: 0.32863369584083557\t Accuracy: 0.6316797137260437\n",
            "Step [296/882]\t Loss: 0.29390984773635864\t Accuracy: 0.6398048996925354\n",
            "Step [297/882]\t Loss: 0.5801655054092407\t Accuracy: 0.5265344977378845\n",
            "Step [298/882]\t Loss: 0.40925902128219604\t Accuracy: 0.5225347876548767\n",
            "Step [299/882]\t Loss: 0.2648526430130005\t Accuracy: 0.630631685256958\n",
            "Step [300/882]\t Loss: 0.28093913197517395\t Accuracy: 0.6103774309158325\n",
            "Step [301/882]\t Loss: 0.24346166849136353\t Accuracy: 0.6302621364593506\n",
            "Step [302/882]\t Loss: 0.4153076410293579\t Accuracy: 0.49082237482070923\n",
            "Step [303/882]\t Loss: 0.3790614902973175\t Accuracy: 0.5061543583869934\n",
            "Step [304/882]\t Loss: 0.23960842192173004\t Accuracy: 0.63958340883255\n",
            "Step [305/882]\t Loss: 0.23593495786190033\t Accuracy: 0.6453349590301514\n",
            "Step [306/882]\t Loss: 0.4372320771217346\t Accuracy: 0.49673792719841003\n",
            "Step [307/882]\t Loss: 0.6615841388702393\t Accuracy: 0.36535346508026123\n",
            "Step [308/882]\t Loss: 0.37867969274520874\t Accuracy: 0.5089956521987915\n",
            "Step [309/882]\t Loss: 0.40435144305229187\t Accuracy: 0.5846404433250427\n",
            "Step [310/882]\t Loss: 0.4575157165527344\t Accuracy: 0.4977625608444214\n",
            "Step [311/882]\t Loss: 0.4540693163871765\t Accuracy: 0.48860543966293335\n",
            "Step [312/882]\t Loss: 0.42492029070854187\t Accuracy: 0.5535733103752136\n",
            "Step [313/882]\t Loss: 0.3074387013912201\t Accuracy: 0.5884379148483276\n",
            "Step [314/882]\t Loss: 0.25758665800094604\t Accuracy: 0.6096150279045105\n",
            "Step [315/882]\t Loss: 0.37646499276161194\t Accuracy: 0.5596495270729065\n",
            "Step [316/882]\t Loss: 0.3203563988208771\t Accuracy: 0.5836896300315857\n",
            "Step [317/882]\t Loss: 0.3111370801925659\t Accuracy: 0.5868766903877258\n",
            "Step [318/882]\t Loss: 0.2082373946905136\t Accuracy: 0.635802149772644\n",
            "Step [319/882]\t Loss: 0.46288806200027466\t Accuracy: 0.48956841230392456\n",
            "Step [320/882]\t Loss: 0.4400204122066498\t Accuracy: 0.5585170984268188\n",
            "Step [321/882]\t Loss: 0.47641634941101074\t Accuracy: 0.4708159863948822\n",
            "Step [322/882]\t Loss: 0.5264626741409302\t Accuracy: 0.38827288150787354\n",
            "Step [323/882]\t Loss: 0.4614231288433075\t Accuracy: 0.5582159161567688\n",
            "Step [324/882]\t Loss: 0.3690609633922577\t Accuracy: 0.5802950263023376\n",
            "Step [325/882]\t Loss: 0.4630669951438904\t Accuracy: 0.5415575504302979\n",
            "Step [326/882]\t Loss: 0.5054607391357422\t Accuracy: 0.5328736901283264\n",
            "Step [327/882]\t Loss: 0.3209930658340454\t Accuracy: 0.5848012566566467\n",
            "Step [328/882]\t Loss: 0.4137934446334839\t Accuracy: 0.5598651170730591\n",
            "Step [329/882]\t Loss: 0.2588832378387451\t Accuracy: 0.6069403290748596\n",
            "Step [330/882]\t Loss: 0.4834747016429901\t Accuracy: 0.4783152639865875\n",
            "Step [331/882]\t Loss: 0.44444867968559265\t Accuracy: 0.5337926149368286\n",
            "Step [332/882]\t Loss: 0.2589859664440155\t Accuracy: 0.6101921200752258\n",
            "Step [333/882]\t Loss: 0.35362479090690613\t Accuracy: 0.5781147480010986\n",
            "Step [334/882]\t Loss: 0.39124807715415955\t Accuracy: 0.48025229573249817\n",
            "Step [335/882]\t Loss: 0.35717928409576416\t Accuracy: 0.5768237113952637\n",
            "Step [336/882]\t Loss: 0.40104904770851135\t Accuracy: 0.5020778775215149\n",
            "Step [337/882]\t Loss: 0.33214709162712097\t Accuracy: 0.5182226896286011\n",
            "Step [338/882]\t Loss: 0.32661402225494385\t Accuracy: 0.5940452814102173\n",
            "Step [339/882]\t Loss: 0.48704734444618225\t Accuracy: 0.4804467558860779\n",
            "Step [340/882]\t Loss: 0.3726116120815277\t Accuracy: 0.5181043148040771\n",
            "Step [341/882]\t Loss: 0.5077536702156067\t Accuracy: 0.46862316131591797\n",
            "Step [342/882]\t Loss: 0.26769840717315674\t Accuracy: 0.6370513439178467\n",
            "Step [343/882]\t Loss: 0.3509526550769806\t Accuracy: 0.5995168089866638\n",
            "Step [344/882]\t Loss: 0.3077099621295929\t Accuracy: 0.6051927804946899\n",
            "Step [345/882]\t Loss: 0.392348051071167\t Accuracy: 0.5884665250778198\n",
            "Step [346/882]\t Loss: 0.23965629935264587\t Accuracy: 0.6486983299255371\n",
            "Step [347/882]\t Loss: 0.3877502381801605\t Accuracy: 0.5278877019882202\n",
            "Step [348/882]\t Loss: 0.3705178201198578\t Accuracy: 0.5956538915634155\n",
            "Step [349/882]\t Loss: 0.598185122013092\t Accuracy: 0.4633857309818268\n",
            "Step [350/882]\t Loss: 0.3434670865535736\t Accuracy: 0.604709804058075\n",
            "Step [351/882]\t Loss: 0.4243236184120178\t Accuracy: 0.563234269618988\n",
            "Step [352/882]\t Loss: 0.2366989254951477\t Accuracy: 0.6447643041610718\n",
            "Step [353/882]\t Loss: 0.23428750038146973\t Accuracy: 0.6479818820953369\n",
            "Step [354/882]\t Loss: 0.2252798229455948\t Accuracy: 0.6504500508308411\n",
            "Step [355/882]\t Loss: 0.3793630599975586\t Accuracy: 0.58284592628479\n",
            "Step [356/882]\t Loss: 0.18751263618469238\t Accuracy: 0.6767432689666748\n",
            "Step [357/882]\t Loss: 0.48551180958747864\t Accuracy: 0.513572633266449\n",
            "Step [358/882]\t Loss: 0.22575601935386658\t Accuracy: 0.6642485857009888\n",
            "Step [359/882]\t Loss: 0.23473498225212097\t Accuracy: 0.6582123041152954\n",
            "Step [360/882]\t Loss: 0.26367703080177307\t Accuracy: 0.6482543349266052\n",
            "Step [361/882]\t Loss: 0.4172752797603607\t Accuracy: 0.5368430614471436\n",
            "Step [362/882]\t Loss: 0.5292134284973145\t Accuracy: 0.49495911598205566\n",
            "Step [363/882]\t Loss: 0.27815526723861694\t Accuracy: 0.6582865118980408\n",
            "Step [364/882]\t Loss: 0.3604831099510193\t Accuracy: 0.606056272983551\n",
            "Step [365/882]\t Loss: 0.5261053442955017\t Accuracy: 0.5036889910697937\n",
            "Step [366/882]\t Loss: 0.303144633769989\t Accuracy: 0.6333506107330322\n",
            "Step [367/882]\t Loss: 0.3344983458518982\t Accuracy: 0.6152811646461487\n",
            "Step [368/882]\t Loss: 0.49646273255348206\t Accuracy: 0.49142327904701233\n",
            "Step [369/882]\t Loss: 0.45532578229904175\t Accuracy: 0.5063151717185974\n",
            "Step [370/882]\t Loss: 0.2819717824459076\t Accuracy: 0.6266537308692932\n",
            "Step [371/882]\t Loss: 0.37506526708602905\t Accuracy: 0.5850611925125122\n",
            "Step [372/882]\t Loss: 0.19342850148677826\t Accuracy: 0.6635515689849854\n",
            "Step [373/882]\t Loss: 0.2812345027923584\t Accuracy: 0.6074024438858032\n",
            "Step [374/882]\t Loss: 0.16268137097358704\t Accuracy: 0.6781336069107056\n",
            "Step [375/882]\t Loss: 0.41833552718162537\t Accuracy: 0.5070868134498596\n",
            "Step [376/882]\t Loss: 0.18979670107364655\t Accuracy: 0.6686251759529114\n",
            "Step [377/882]\t Loss: 0.37777945399284363\t Accuracy: 0.5228955149650574\n",
            "Step [378/882]\t Loss: 0.4053817391395569\t Accuracy: 0.530997633934021\n",
            "Step [379/882]\t Loss: 0.24060770869255066\t Accuracy: 0.6525755524635315\n",
            "Step [380/882]\t Loss: 0.30683383345603943\t Accuracy: 0.6268771290779114\n",
            "Step [381/882]\t Loss: 0.46589452028274536\t Accuracy: 0.5053525567054749\n",
            "Step [382/882]\t Loss: 0.2335173785686493\t Accuracy: 0.6675207614898682\n",
            "Step [383/882]\t Loss: 0.5074665546417236\t Accuracy: 0.5163008570671082\n",
            "Step [384/882]\t Loss: 0.3156283497810364\t Accuracy: 0.6299654841423035\n",
            "Step [385/882]\t Loss: 0.41380712389945984\t Accuracy: 0.5977632999420166\n",
            "Step [386/882]\t Loss: 0.5761206150054932\t Accuracy: 0.49967852234840393\n",
            "Step [387/882]\t Loss: 0.5704607963562012\t Accuracy: 0.46672818064689636\n",
            "Step [388/882]\t Loss: 0.3808322846889496\t Accuracy: 0.5218387246131897\n",
            "Step [389/882]\t Loss: 0.3346429467201233\t Accuracy: 0.5379067063331604\n",
            "Step [390/882]\t Loss: 0.4231475591659546\t Accuracy: 0.49388062953948975\n",
            "Step [391/882]\t Loss: 0.4578361213207245\t Accuracy: 0.48083817958831787\n",
            "Step [392/882]\t Loss: 0.32345905900001526\t Accuracy: 0.5843389630317688\n",
            "Step [393/882]\t Loss: 0.35015901923179626\t Accuracy: 0.5608912706375122\n",
            "Step [394/882]\t Loss: 0.2924944758415222\t Accuracy: 0.5900128483772278\n",
            "Step [395/882]\t Loss: 0.34246063232421875\t Accuracy: 0.5722285509109497\n",
            "Step [396/882]\t Loss: 0.7324793934822083\t Accuracy: 0.3550189733505249\n",
            "Step [397/882]\t Loss: 0.6019972562789917\t Accuracy: 0.4562726318836212\n",
            "Step [398/882]\t Loss: 0.33159124851226807\t Accuracy: 0.5642330646514893\n",
            "Step [399/882]\t Loss: 0.30273860692977905\t Accuracy: 0.5576400756835938\n",
            "Step [400/882]\t Loss: 0.5395760536193848\t Accuracy: 0.431024968624115\n",
            "Step [401/882]\t Loss: 0.48359769582748413\t Accuracy: 0.44311460852622986\n",
            "Step [402/882]\t Loss: 0.4020611643791199\t Accuracy: 0.4647514522075653\n",
            "Step [403/882]\t Loss: 0.28509521484375\t Accuracy: 0.5692294836044312\n",
            "Step [404/882]\t Loss: 0.29398053884506226\t Accuracy: 0.5682243704795837\n",
            "Step [405/882]\t Loss: 0.39987289905548096\t Accuracy: 0.4723716676235199\n",
            "Step [406/882]\t Loss: 0.385041743516922\t Accuracy: 0.47857561707496643\n",
            "Step [407/882]\t Loss: 0.4101017117500305\t Accuracy: 0.5347694754600525\n",
            "Step [408/882]\t Loss: 0.4184853434562683\t Accuracy: 0.5445308089256287\n",
            "Step [409/882]\t Loss: 0.6484403014183044\t Accuracy: 0.3406554162502289\n",
            "Step [410/882]\t Loss: 0.44751644134521484\t Accuracy: 0.5271589756011963\n",
            "Step [411/882]\t Loss: 0.3864488899707794\t Accuracy: 0.5570136904716492\n",
            "Step [412/882]\t Loss: 0.38481059670448303\t Accuracy: 0.5399041771888733\n",
            "Step [413/882]\t Loss: 0.4049270451068878\t Accuracy: 0.5436761379241943\n",
            "Step [414/882]\t Loss: 0.5805119276046753\t Accuracy: 0.4539039134979248\n",
            "Step [415/882]\t Loss: 0.23409178853034973\t Accuracy: 0.6077008247375488\n",
            "Step [416/882]\t Loss: 0.47052082419395447\t Accuracy: 0.5361032485961914\n",
            "Step [417/882]\t Loss: 0.4810541868209839\t Accuracy: 0.4672730267047882\n",
            "Step [418/882]\t Loss: 0.4040640592575073\t Accuracy: 0.4845770299434662\n",
            "Step [419/882]\t Loss: 0.4686290919780731\t Accuracy: 0.4941161572933197\n",
            "Step [420/882]\t Loss: 0.41179463267326355\t Accuracy: 0.48978811502456665\n",
            "Step [421/882]\t Loss: 0.43028396368026733\t Accuracy: 0.5349624752998352\n",
            "Step [422/882]\t Loss: 0.3715323507785797\t Accuracy: 0.5211088061332703\n",
            "Step [423/882]\t Loss: 0.28374025225639343\t Accuracy: 0.5880954265594482\n",
            "Step [424/882]\t Loss: 0.3879401385784149\t Accuracy: 0.47752678394317627\n",
            "Step [425/882]\t Loss: 0.40642601251602173\t Accuracy: 0.5618037581443787\n",
            "Step [426/882]\t Loss: 0.23425380885601044\t Accuracy: 0.6142119765281677\n",
            "Step [427/882]\t Loss: 0.34735849499702454\t Accuracy: 0.5661488175392151\n",
            "Step [428/882]\t Loss: 0.19580882787704468\t Accuracy: 0.6436964273452759\n",
            "Step [429/882]\t Loss: 0.5422368049621582\t Accuracy: 0.481321781873703\n",
            "Step [430/882]\t Loss: 0.44938933849334717\t Accuracy: 0.4956675171852112\n",
            "Step [431/882]\t Loss: 0.31639546155929565\t Accuracy: 0.6154809594154358\n",
            "Step [432/882]\t Loss: 0.6452378630638123\t Accuracy: 0.36640337109565735\n",
            "Step [433/882]\t Loss: 0.3563031256198883\t Accuracy: 0.5977314710617065\n",
            "Step [434/882]\t Loss: 0.5250670909881592\t Accuracy: 0.47324138879776\n",
            "Step [435/882]\t Loss: 0.35606542229652405\t Accuracy: 0.5775759816169739\n",
            "Step [436/882]\t Loss: 0.33958700299263\t Accuracy: 0.5928958058357239\n",
            "Step [437/882]\t Loss: 0.30443480610847473\t Accuracy: 0.5943170189857483\n",
            "Step [438/882]\t Loss: 0.3102104067802429\t Accuracy: 0.5993160605430603\n",
            "Step [439/882]\t Loss: 0.34578144550323486\t Accuracy: 0.5097522139549255\n",
            "Step [440/882]\t Loss: 0.47610437870025635\t Accuracy: 0.5447622537612915\n",
            "Step [441/882]\t Loss: 0.34091365337371826\t Accuracy: 0.5098810791969299\n",
            "Step [442/882]\t Loss: 0.29340746998786926\t Accuracy: 0.6025184392929077\n",
            "Step [443/882]\t Loss: 0.31233271956443787\t Accuracy: 0.5998457074165344\n",
            "Step [444/882]\t Loss: 0.2520830035209656\t Accuracy: 0.6261197328567505\n",
            "Step [445/882]\t Loss: 0.21431732177734375\t Accuracy: 0.6485456824302673\n",
            "Step [446/882]\t Loss: 0.2541956305503845\t Accuracy: 0.6376451253890991\n",
            "Step [447/882]\t Loss: 0.38493862748146057\t Accuracy: 0.5253019332885742\n",
            "Step [448/882]\t Loss: 0.4598851799964905\t Accuracy: 0.5660602450370789\n",
            "Step [449/882]\t Loss: 0.6726137399673462\t Accuracy: 0.36879295110702515\n",
            "Step [450/882]\t Loss: 0.19384948909282684\t Accuracy: 0.6719592213630676\n",
            "Step [451/882]\t Loss: 0.4236871004104614\t Accuracy: 0.5168125033378601\n",
            "Step [452/882]\t Loss: 0.33152902126312256\t Accuracy: 0.6173931360244751\n",
            "Step [453/882]\t Loss: 0.38774383068084717\t Accuracy: 0.5156738758087158\n",
            "Step [454/882]\t Loss: 0.19829902052879333\t Accuracy: 0.666057825088501\n",
            "Step [455/882]\t Loss: 0.3409956991672516\t Accuracy: 0.5322586297988892\n",
            "Step [456/882]\t Loss: 0.3399536609649658\t Accuracy: 0.5419480204582214\n",
            "Step [457/882]\t Loss: 0.28520724177360535\t Accuracy: 0.6280539631843567\n",
            "Step [458/882]\t Loss: 0.27284345030784607\t Accuracy: 0.6459193825721741\n",
            "Step [459/882]\t Loss: 0.3307684063911438\t Accuracy: 0.6140561103820801\n",
            "Step [460/882]\t Loss: 0.3339326083660126\t Accuracy: 0.6226072311401367\n",
            "Step [461/882]\t Loss: 0.5304017066955566\t Accuracy: 0.42975080013275146\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-38e6d4b0e33c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mloss_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimclr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-3154e0d79b3c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, loader, simclr_model, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m#output.grad.zero()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m#with torch.no_grad():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mloss_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.22 GiB (GPU 0; 15.90 GiB total capacity; 13.80 GiB already allocated; 1.22 GiB free; 13.90 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWXxAGO2_VYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-84n0Byv_VYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvV8SRFY_VYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}